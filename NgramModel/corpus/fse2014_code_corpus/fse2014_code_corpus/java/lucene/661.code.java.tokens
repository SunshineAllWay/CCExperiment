package org . apache . lucene . analysis . fr ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . CharArraySet ; import org . apache . lucene . analysis . LowerCaseFilter ; import org . apache . lucene . analysis . KeywordMarkerTokenFilter ; import org . apache . lucene . analysis . StopFilter ; import org . apache . lucene . analysis . StopwordAnalyzerBase ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . analysis . Tokenizer ; import org . apache . lucene . analysis . WordlistLoader ; import org . apache . lucene . analysis . snowball . SnowballFilter ; import org . apache . lucene . analysis . standard . StandardFilter ; import org . apache . lucene . analysis . standard . StandardTokenizer ; import org . apache . lucene . analysis . standard . StandardAnalyzer ; import org . apache . lucene . util . Version ; import java . io . File ; import java . io . IOException ; import java . io . Reader ; import java . util . Arrays ; import java . util . HashSet ; import java . util . Collections ; import java . util . Map ; import java . util . Set ; public final class FrenchAnalyzer extends StopwordAnalyzerBase { @ Deprecated public final static String [ ] FRENCH_STOP_WORDS = { "a" , "afin" , "ai" , "ainsi" , "après" , "attendu" , "au" , "aujourd" , "auquel" , "aussi" , "autre" , "autres" , "aux" , "auxquelles" , "auxquels" , "avait" , "avant" , "avec" , "avoir" , "c" , "car" , "ce" , "ceci" , "cela" , "celle" , "celles" , "celui" , "cependant" , "certain" , "certaine" , "certaines" , "certains" , "ces" , "cet" , "cette" , "ceux" , "chez" , "ci" , "combien" , "comme" , "comment" , "concernant" , "contre" , "d" , "dans" , "de" , "debout" , "dedans" , "dehors" , "delà" , "depuis" , "derrière" , "des" , "désormais" , "desquelles" , "desquels" , "dessous" , "dessus" , "devant" , "devers" , "devra" , "divers" , "diverse" , "diverses" , "doit" , "donc" , "dont" , "du" , "duquel" , "durant" , "dès" , "elle" , "elles" , "en" , "entre" , "environ" , "est" , "et" , "etc" , "etre" , "eu" , "eux" , "excepté" , "hormis" , "hors" , "hélas" , "hui" , "il" , "ils" , "j" , "je" , "jusqu" , "jusque" , "l" , "la" , "laquelle" , "le" , "lequel" , "les" , "lesquelles" , "lesquels" , "leur" , "leurs" , "lorsque" , "lui" , "là" , "ma" , "mais" , "malgré" , "me" , "merci" , "mes" , "mien" , "mienne" , "miennes" , "miens" , "moi" , "moins" , "mon" , "moyennant" , "même" , "mêmes" , "n" , "ne" , "ni" , "non" , "nos" , "notre" , "nous" , "néanmoins" , "nôtre" , "nôtres" , "on" , "ont" , "ou" , "outre" , "où" , "par" , "parmi" , "partant" , "pas" , "passé" , "pendant" , "plein" , "plus" , "plusieurs" , "pour" , "pourquoi" , "proche" , "près" , "puisque" , "qu" , "quand" , "que" , "quel" , "quelle" , "quelles" , "quels" , "qui" , "quoi" , "quoique" , "revoici" , "revoilà" , "s" , "sa" , "sans" , "sauf" , "se" , "selon" , "seront" , "ses" , "si" , "sien" , "sienne" , "siennes" , "siens" , "sinon" , "soi" , "soit" , "son" , "sont" , "sous" , "suivant" , "sur" , "ta" , "te" , "tes" , "tien" , "tienne" , "tiennes" , "tiens" , "toi" , "ton" , "tous" , "tout" , "toute" , "toutes" , "tu" , "un" , "une" , "va" , "vers" , "voici" , "voilà" , "vos" , "votre" , "vous" , "vu" , "vôtre" , "vôtres" , "y" , "à" , "ça" , "ès" , "été" , "être" , "ô" } ; public final static String DEFAULT_STOPWORD_FILE = "french_stop.txt" ; private Set < ? > excltable = Collections . < Object > emptySet ( ) ; public static Set < ? > getDefaultStopSet ( ) { return DefaultSetHolder . DEFAULT_STOP_SET ; } private static class DefaultSetHolder { @ Deprecated static final Set < ? > DEFAULT_STOP_SET_30 = CharArraySet . unmodifiableSet ( new CharArraySet ( Version . LUCENE_CURRENT , Arrays . asList ( FRENCH_STOP_WORDS ) , false ) ) ; static final Set < ? > DEFAULT_STOP_SET ; static { try { DEFAULT_STOP_SET = WordlistLoader . getSnowballWordSet ( SnowballFilter . class , DEFAULT_STOPWORD_FILE ) ; } catch ( IOException ex ) { throw new RuntimeException ( "Unable to load default stopword set" ) ; } } } public FrenchAnalyzer ( Version matchVersion ) { this ( matchVersion , matchVersion . onOrAfter ( Version . LUCENE_31 ) ? DefaultSetHolder . DEFAULT_STOP_SET : DefaultSetHolder . DEFAULT_STOP_SET_30 ) ; } public FrenchAnalyzer ( Version matchVersion , Set < ? > stopwords ) { this ( matchVersion , stopwords , CharArraySet . EMPTY_SET ) ; } public FrenchAnalyzer ( Version matchVersion , Set < ? > stopwords , Set < ? > stemExclutionSet ) { super ( matchVersion , stopwords ) ; this . excltable = CharArraySet . unmodifiableSet ( CharArraySet . copy ( matchVersion , stemExclutionSet ) ) ; } @ Deprecated public FrenchAnalyzer ( Version matchVersion , String ... stopwords ) { this ( matchVersion , StopFilter . makeStopSet ( matchVersion , stopwords ) ) ; } @ Deprecated public FrenchAnalyzer ( Version matchVersion , File stopwords ) throws IOException { this ( matchVersion , WordlistLoader . getWordSet ( stopwords ) ) ; } @ Deprecated public void setStemExclusionTable ( String ... exclusionlist ) { excltable = StopFilter . makeStopSet ( matchVersion , exclusionlist ) ; setPreviousTokenStream ( null ) ; } @ Deprecated public void setStemExclusionTable ( Map < ? , ? > exclusionlist ) { excltable = new HashSet < Object > ( exclusionlist . keySet ( ) ) ; setPreviousTokenStream ( null ) ; } @ Deprecated public void setStemExclusionTable ( File exclusionlist ) throws IOException { excltable = new HashSet < Object > ( WordlistLoader . getWordSet ( exclusionlist ) ) ; setPreviousTokenStream ( null ) ; } @ Override protected TokenStreamComponents createComponents ( String fieldName , Reader reader ) { if ( matchVersion . onOrAfter ( Version . LUCENE_31 ) ) { final Tokenizer source = new StandardTokenizer ( matchVersion , reader ) ; TokenStream result = new StandardFilter ( source ) ; result = new ElisionFilter ( matchVersion , result ) ; result = new LowerCaseFilter ( matchVersion , result ) ; result = new StopFilter ( matchVersion , result , stopwords ) ; if ( ! excltable . isEmpty ( ) ) result = new KeywordMarkerTokenFilter ( result , excltable ) ; result = new SnowballFilter ( result , new org . tartarus . snowball . ext . FrenchStemmer ( ) ) ; return new TokenStreamComponents ( source , result ) ; } else { final Tokenizer source = new StandardTokenizer ( matchVersion , reader ) ; TokenStream result = new StandardFilter ( source ) ; result = new StopFilter ( matchVersion , result , stopwords ) ; if ( ! excltable . isEmpty ( ) ) result = new KeywordMarkerTokenFilter ( result , excltable ) ; result = new FrenchStemFilter ( result ) ; return new TokenStreamComponents ( source , new LowerCaseFilter ( matchVersion , result ) ) ; } } }
