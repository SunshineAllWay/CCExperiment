try : frozenset except NameError : from sets import Set as set from sets import ImmutableSet as frozenset try : from collections import deque except ImportError : from utils import deque from constants import contentModelFlags , spaceCharacters from constants import entitiesWindows1252 , entities from constants import asciiLowercase , asciiLetters , asciiUpper2Lower from constants import digits , hexDigits , EOF from constants import tokenTypes , tagTokenTypes from inputstream import HTMLInputStream entitiesByFirstChar = { } for e in entities : entitiesByFirstChar . setdefault ( e [ 0 ] , [ ] ) . append ( e ) class HTMLTokenizer : def __init__ ( self , stream , encoding = None , parseMeta = True , useChardet = True , lowercaseElementName = True , lowercaseAttrName = True ) : self . stream = HTMLInputStream ( stream , encoding , parseMeta , useChardet ) self . lowercaseElementName = lowercaseElementName self . lowercaseAttrName = lowercaseAttrName self . states = { : self . dataState , : self . entityDataState , : self . tagOpenState , : self . closeTagOpenState , : self . tagNameState , : self . beforeAttributeNameState , : self . attributeNameState , : self . afterAttributeNameState , : self . beforeAttributeValueState , : self . attributeValueDoubleQuotedState , : self . attributeValueSingleQuotedState , : self . attributeValueUnQuotedState , : self . afterAttributeValueState , : self . selfClosingStartTagState , : self . bogusCommentState , : self . bogusCommentContinuationState , : self . markupDeclarationOpenState , : self . commentStartState , : self . commentStartDashState , : self . commentState , : self . commentEndDashState , : self . commentEndState , : self . commentEndBangState , : self . commentEndSpaceState , : self . doctypeState , : self . beforeDoctypeNameState , : self . doctypeNameState , : self . afterDoctypeNameState , : self . beforeDoctypePublicIdentifierState , : self . doctypePublicIdentifierDoubleQuotedState , : self . doctypePublicIdentifierSingleQuotedState , : self . afterDoctypePublicIdentifierState , : self . beforeDoctypeSystemIdentifierState , : self . doctypeSystemIdentifierDoubleQuotedState , : self . doctypeSystemIdentifierSingleQuotedState , : self . afterDoctypeSystemIdentifierState , : self . bogusDoctypeState } self . contentModelFlag = contentModelFlags [ "PCDATA" ] self . escapeFlag = False self . lastFourChars = [ ] self . state = self . dataState self . escape = False self . currentToken = None def __iter__ ( self ) : self . tokenQueue = deque ( [ ] ) while self . state ( ) : while self . stream . errors : yield { "type" : tokenTypes [ "ParseError" ] , "data" : self . stream . errors . pop ( 0 ) } while self . tokenQueue : yield self . tokenQueue . popleft ( ) def consumeNumberEntity ( self , isHex ) : allowed = digits radix = 10 if isHex : allowed = hexDigits radix = 16 charStack = [ ] c = self . stream . char ( ) while c in allowed and c is not EOF : charStack . append ( c ) c = self . stream . char ( ) charAsInt = int ( "" . join ( charStack ) , radix ) if charAsInt == 13 : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) charAsInt = 10 elif 127 < charAsInt < 160 : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) charAsInt = entitiesWindows1252 [ charAsInt - 128 ] if ( ( charAsInt <= 0x0008 ) or ( charAsInt == 0x000B ) or ( 0x000E <= charAsInt <= 0x001F ) or ( 0x007F <= charAsInt <= 0x009F ) or ( 0xD800 <= charAsInt <= 0xDFFF ) or ( 0xFDD0 <= charAsInt <= 0xFDEF ) or ( charAsInt & 0xFFFE == 0xFFFE ) or ( 0x10FFFF < charAsInt ) ) : char = u"\uFFFD" self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : , : { "charAsInt" : charAsInt } } ) else : try : char = unichr ( charAsInt ) except : try : char = eval ( "u'\\U%08x'" % charAsInt ) except : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : , : { "charAsInt" : charAsInt } } ) if c != u";" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . stream . unget ( c ) return char def consumeEntity ( self , allowedChar = None , fromAttribute = False ) : output = u"&" charStack = [ self . stream . char ( ) ] if charStack [ 0 ] in spaceCharacters or charStack [ 0 ] in ( EOF , u"<" , u"&" ) or ( allowedChar is not None and allowedChar == charStack [ 0 ] ) : self . stream . unget ( charStack [ 0 ] ) elif charStack [ 0 ] == u"#" : hex = False charStack . append ( self . stream . char ( ) ) if charStack [ - 1 ] in ( u"x" , u"X" ) : hex = True charStack . append ( self . stream . char ( ) ) if ( hex and charStack [ - 1 ] in hexDigits ) or ( not hex and charStack [ - 1 ] in digits ) : self . stream . unget ( charStack [ - 1 ] ) output = self . consumeNumberEntity ( hex ) else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , : "expected-numeric-entity" } ) self . stream . unget ( charStack . pop ( ) ) output = u"&" + u"" . join ( charStack ) else : filteredEntityList = entitiesByFirstChar . get ( charStack [ 0 ] , [ ] ) def entitiesStartingWith ( name ) : return [ e for e in filteredEntityList if e . startswith ( name ) ] while charStack [ - 1 ] is not EOF and entitiesStartingWith ( "" . join ( charStack ) ) : charStack . append ( self . stream . char ( ) ) entityName = None for entityLength in xrange ( len ( charStack ) - 1 , 1 , - 1 ) : possibleEntityName = "" . join ( charStack [ : entityLength ] ) if possibleEntityName in entities : entityName = possibleEntityName break if entityName is not None : if entityName [ - 1 ] != ";" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) if entityName [ - 1 ] != ";" and fromAttribute and ( charStack [ entityLength ] in asciiLetters or charStack [ entityLength ] in digits ) : self . stream . unget ( charStack . pop ( ) ) output = u"&" + u"" . join ( charStack ) else : output = entities [ entityName ] self . stream . unget ( charStack . pop ( ) ) output += u"" . join ( charStack [ entityLength : ] ) else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . stream . unget ( charStack . pop ( ) ) output = u"&" + u"" . join ( charStack ) if fromAttribute : self . currentToken [ "data" ] [ - 1 ] [ 1 ] += output else : self . tokenQueue . append ( { "type" : tokenTypes [ "Characters" ] , "data" : output } ) def processEntityInAttribute ( self , allowedChar ) : self . consumeEntity ( allowedChar = allowedChar , fromAttribute = True ) def emitCurrentToken ( self ) : token = self . currentToken if ( token [ "type" ] in tagTokenTypes ) : if self . lowercaseElementName : token [ "name" ] = token [ "name" ] . translate ( asciiUpper2Lower ) if token [ "type" ] == tokenTypes [ "EndTag" ] : if token [ "data" ] : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , : "attributes-in-end-tag" } ) if token [ "selfClosing" ] : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , : "self-closing-flag-on-end-tag" } ) self . tokenQueue . append ( token ) self . state = self . dataState def dataState ( self ) : data = self . stream . char ( ) if ( self . contentModelFlag in ( contentModelFlags [ "CDATA" ] , contentModelFlags [ "RCDATA" ] ) ) : if len ( self . lastFourChars ) == 4 : self . lastFourChars . pop ( 0 ) self . lastFourChars . append ( data ) if ( data == "&" and self . contentModelFlag in ( contentModelFlags [ "PCDATA" ] , contentModelFlags [ "RCDATA" ] ) and not self . escapeFlag ) : self . state = self . states [ "entityData" ] elif ( data == "-" and self . contentModelFlag in ( contentModelFlags [ "CDATA" ] , contentModelFlags [ "RCDATA" ] ) and not self . escapeFlag and "" . join ( self . lastFourChars ) == "<!--" ) : self . escapeFlag = True self . tokenQueue . append ( { "type" : tokenTypes [ "Characters" ] , : data } ) elif ( data == "<" and ( self . contentModelFlag == contentModelFlags [ "PCDATA" ] or ( self . contentModelFlag in ( contentModelFlags [ "CDATA" ] , contentModelFlags [ "RCDATA" ] ) and self . escapeFlag == False ) ) ) : self . state = self . states [ "tagOpen" ] elif ( data == ">" and self . contentModelFlag in ( contentModelFlags [ "CDATA" ] , contentModelFlags [ "RCDATA" ] ) and self . escapeFlag and "" . join ( self . lastFourChars ) [ 1 : ] == "-->" ) : self . escapeFlag = False self . tokenQueue . append ( { "type" : tokenTypes [ "Characters" ] , "data" : data } ) elif data is EOF : return False elif data in spaceCharacters : self . tokenQueue . append ( { "type" : tokenTypes [ "SpaceCharacters" ] , "data" : data + self . stream . charsUntil ( spaceCharacters , True ) } ) else : if ( self . contentModelFlag in ( contentModelFlags [ "CDATA" ] , contentModelFlags [ "RCDATA" ] ) ) : chars = self . stream . charsUntil ( ( u"&" , u"<" , u">" , u"-" ) ) self . lastFourChars += chars [ - 4 : ] self . lastFourChars = self . lastFourChars [ - 4 : ] else : chars = self . stream . charsUntil ( ( u"&" , u"<" ) ) self . tokenQueue . append ( { "type" : tokenTypes [ "Characters" ] , "data" : data + chars } ) return True def entityDataState ( self ) : self . consumeEntity ( ) self . state = self . states [ "data" ] return True def tagOpenState ( self ) : data = self . stream . char ( ) if self . contentModelFlag == contentModelFlags [ "PCDATA" ] : if data == u"!" : self . state = self . states [ "markupDeclarationOpen" ] elif data == u"/" : self . state = self . states [ "closeTagOpen" ] elif data in asciiLetters : self . currentToken = { "type" : tokenTypes [ "StartTag" ] , : data , "data" : [ ] , : False , : False } self . state = self . states [ "tagName" ] elif data == u">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( { "type" : tokenTypes [ "Characters" ] , "data" : u"<>" } ) self . state = self . states [ "data" ] elif data == u"?" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . stream . unget ( data ) self . state = self . states [ "bogusComment" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( { "type" : tokenTypes [ "Characters" ] , "data" : u"<" } ) self . stream . unget ( data ) self . state = self . states [ "data" ] else : if data == u"/" : self . state = self . states [ "closeTagOpen" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "Characters" ] , "data" : u"<" } ) self . stream . unget ( data ) self . state = self . states [ "data" ] return True def closeTagOpenState ( self ) : if ( self . contentModelFlag in ( contentModelFlags [ "RCDATA" ] , contentModelFlags [ "CDATA" ] ) ) : charStack = [ ] if self . currentToken : matched = True for expected in self . currentToken [ "name" ] . lower ( ) : charStack . append ( self . stream . char ( ) ) if charStack [ - 1 ] not in ( expected , expected . upper ( ) ) : matched = False break if matched : charStack . append ( self . stream . char ( ) ) if charStack [ - 1 ] in ( spaceCharacters | frozenset ( ( u">" , u"/" , EOF ) ) ) : self . contentModelFlag = contentModelFlags [ "PCDATA" ] self . stream . unget ( charStack . pop ( ) ) self . currentToken = { "type" : tokenTypes [ "EndTag" ] , : u"" . join ( charStack ) , : [ ] , : False } self . state = self . states [ "tagName" ] return True self . stream . unget ( charStack . pop ( ) ) self . tokenQueue . append ( { "type" : tokenTypes [ "Characters" ] , "data" : u"</" + u"" . join ( charStack ) } ) self . state = self . states [ "data" ] return True data = self . stream . char ( ) if data in asciiLetters : self . currentToken = { "type" : tokenTypes [ "EndTag" ] , "name" : data , : [ ] , "selfClosing" : False } self . state = self . states [ "tagName" ] elif data == u">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( { "type" : tokenTypes [ "Characters" ] , "data" : u"</" } ) self . state = self . states [ "data" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : , : { "data" : data } } ) self . stream . unget ( data ) self . state = self . states [ "bogusComment" ] return True def tagNameState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : self . state = self . states [ "beforeAttributeName" ] elif data == u">" : self . emitCurrentToken ( ) elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . state = self . states [ "data" ] elif data == u"/" : self . state = self . states [ "selfClosingStartTag" ] else : self . currentToken [ "name" ] += data return True def beforeAttributeNameState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : self . stream . charsUntil ( spaceCharacters , True ) elif data in asciiLetters : self . currentToken [ "data" ] . append ( [ data , "" ] ) self . state = self . states [ "attributeName" ] elif data == u">" : self . emitCurrentToken ( ) elif data == u"/" : self . state = self . states [ "selfClosingStartTag" ] elif data == u"'" or data == u'"' or data == u"=" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "data" ] . append ( [ data , "" ] ) self . state = self . states [ "attributeName" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . state = self . states [ "data" ] else : self . currentToken [ "data" ] . append ( [ data , "" ] ) self . state = self . states [ "attributeName" ] return True def attributeNameState ( self ) : data = self . stream . char ( ) leavingThisState = True emitToken = False if data == u"=" : self . state = self . states [ "beforeAttributeValue" ] elif data in asciiLetters : self . currentToken [ "data" ] [ - 1 ] [ 0 ] += data + self . stream . charsUntil ( asciiLetters , True ) leavingThisState = False elif data == u">" : emitToken = True elif data in spaceCharacters : self . state = self . states [ "afterAttributeName" ] elif data == u"/" : self . state = self . states [ "selfClosingStartTag" ] elif data == u"'" or data == u'"' : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "data" ] [ - 1 ] [ 0 ] += data leavingThisState = False elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . state = self . states [ "data" ] emitToken = True else : self . currentToken [ "data" ] [ - 1 ] [ 0 ] += data leavingThisState = False if leavingThisState : if self . lowercaseAttrName : self . currentToken [ "data" ] [ - 1 ] [ 0 ] = ( self . currentToken [ "data" ] [ - 1 ] [ 0 ] . translate ( asciiUpper2Lower ) ) for name , value in self . currentToken [ "data" ] [ : - 1 ] : if self . currentToken [ "data" ] [ - 1 ] [ 0 ] == name : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) break if emitToken : self . emitCurrentToken ( ) return True def afterAttributeNameState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : self . stream . charsUntil ( spaceCharacters , True ) elif data == u"=" : self . state = self . states [ "beforeAttributeValue" ] elif data == u">" : self . emitCurrentToken ( ) elif data in asciiLetters : self . currentToken [ "data" ] . append ( [ data , "" ] ) self . state = self . states [ "attributeName" ] elif data == u"/" : self . state = self . states [ "selfClosingStartTag" ] elif data == u"'" or data == u'"' : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "data" ] . append ( [ data , "" ] ) self . state = self . states [ "attributeName" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . emitCurrentToken ( ) else : self . currentToken [ "data" ] . append ( [ data , "" ] ) self . state = self . states [ "attributeName" ] return True def beforeAttributeValueState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : self . stream . charsUntil ( spaceCharacters , True ) elif data == u"\"" : self . state = self . states [ "attributeValueDoubleQuoted" ] elif data == u"&" : self . state = self . states [ "attributeValueUnQuoted" ] self . stream . unget ( data ) ; elif data == u"'" : self . state = self . states [ "attributeValueSingleQuoted" ] elif data == u">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . emitCurrentToken ( ) elif data == u"=" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "data" ] [ - 1 ] [ 1 ] += data self . state = self . states [ "attributeValueUnQuoted" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . emitCurrentToken ( ) else : self . currentToken [ "data" ] [ - 1 ] [ 1 ] += data self . state = self . states [ "attributeValueUnQuoted" ] return True def attributeValueDoubleQuotedState ( self ) : data = self . stream . char ( ) if data == "\"" : self . state = self . states [ "afterAttributeValue" ] elif data == u"&" : self . processEntityInAttribute ( u'"' ) elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . emitCurrentToken ( ) else : self . currentToken [ "data" ] [ - 1 ] [ 1 ] += data + self . stream . charsUntil ( ( "\"" , u"&" ) ) return True def attributeValueSingleQuotedState ( self ) : data = self . stream . char ( ) if data == "'" : self . state = self . states [ "afterAttributeValue" ] elif data == u"&" : self . processEntityInAttribute ( u"'" ) elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . emitCurrentToken ( ) else : self . currentToken [ "data" ] [ - 1 ] [ 1 ] += data + self . stream . charsUntil ( ( "'" , u"&" ) ) return True def attributeValueUnQuotedState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : self . state = self . states [ "beforeAttributeName" ] elif data == u"&" : self . processEntityInAttribute ( None ) elif data == u">" : self . emitCurrentToken ( ) elif data in ( u'"' , u"'" , u"=" , u"<" ) : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "data" ] [ - 1 ] [ 1 ] += data elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . emitCurrentToken ( ) else : self . currentToken [ "data" ] [ - 1 ] [ 1 ] += data + self . stream . charsUntil ( frozenset ( ( "&" , ">" , "<" , "=" , "'" , '"' ) ) | spaceCharacters ) return True def afterAttributeValueState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : self . state = self . states [ "beforeAttributeName" ] elif data == u">" : self . emitCurrentToken ( ) elif data == u"/" : self . state = self . states [ "selfClosingStartTag" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . emitCurrentToken ( ) self . stream . unget ( data ) self . state = self . states [ "data" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . stream . unget ( data ) self . state = self . states [ "beforeAttributeName" ] return True def selfClosingStartTagState ( self ) : data = self . stream . char ( ) if data == ">" : self . currentToken [ "selfClosing" ] = True self . emitCurrentToken ( ) elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , : } ) self . stream . unget ( data ) self . state = self . states [ "data" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . stream . unget ( data ) self . state = self . states [ "beforeAttributeName" ] return True def bogusCommentState ( self ) : self . tokenQueue . append ( { "type" : tokenTypes [ "Comment" ] , "data" : self . stream . charsUntil ( u">" ) } ) self . stream . char ( ) self . state = self . states [ "data" ] return True def bogusCommentContinuationState ( self ) : self . currentToken [ "data" ] += self . stream . charsUntil ( u">" ) self . tokenQueue . append ( self . currentToken ) self . stream . char ( ) self . state = self . states [ "data" ] return True def markupDeclarationOpenState ( self ) : charStack = [ self . stream . char ( ) ] if charStack [ - 1 ] == u"-" : charStack . append ( self . stream . char ( ) ) if charStack [ - 1 ] == u"-" : self . currentToken = { "type" : tokenTypes [ "Comment" ] , "data" : u"" } self . state = self . states [ "commentStart" ] return True elif charStack [ - 1 ] in ( u'd' , u'D' ) : matched = True for expected in ( ( u'o' , u'O' ) , ( u'c' , u'C' ) , ( u't' , u'T' ) , ( u'y' , u'Y' ) , ( u'p' , u'P' ) , ( u'e' , u'E' ) ) : charStack . append ( self . stream . char ( ) ) if charStack [ - 1 ] not in expected : matched = False break if matched : self . currentToken = { "type" : tokenTypes [ "Doctype" ] , : u"" , : None , "systemId" : None , : True } self . state = self . states [ "doctype" ] return True self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . stream . unget ( charStack . pop ( ) ) self . currentToken = { "type" : tokenTypes [ "Comment" ] , : u"" . join ( charStack ) } self . state = self . states [ "bogusCommentContinuation" ] return True def commentStartState ( self ) : data = self . stream . char ( ) if data == "-" : self . state = self . states [ "commentStartDash" ] elif data == ">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "data" ] += data + self . stream . charsUntil ( u"-" ) self . state = self . states [ "comment" ] return True def commentStartDashState ( self ) : data = self . stream . char ( ) if data == "-" : self . state = self . states [ "commentEnd" ] elif data == ">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "data" ] += "-" + data + self . stream . charsUntil ( u"-" ) self . state = self . states [ "comment" ] return True def commentState ( self ) : data = self . stream . char ( ) if data == u"-" : self . state = self . states [ "commentEndDash" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "data" ] += data + self . stream . charsUntil ( u"-" ) return True def commentEndDashState ( self ) : data = self . stream . char ( ) if data == u"-" : self . state = self . states [ "commentEnd" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "data" ] += u"-" + data + self . stream . charsUntil ( u"-" ) self . stream . char ( ) return True def commentEndState ( self ) : data = self . stream . char ( ) if data == u">" : self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data == u"-" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "data" ] += data elif data in spaceCharacters : self . currentToken [ "data" ] += "--" + data self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . state = self . states [ "commentEndSpace" ] elif data == "!" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . state = self . states [ "commentEndBang" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "data" ] += u"--" + data self . state = self . states [ "comment" ] return True def commentEndBangState ( self ) : data = self . stream . char ( ) if data == u">" : self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data == u"-" : self . currentToken [ "data" ] += "--!" self . state = self . states [ "commentEndDash" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "data" ] += u"--!" + data self . state = self . states [ "comment" ] return True def commentEndSpaceState ( self ) : data = self . stream . char ( ) if data == u">" : self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data == u"-" : self . state = self . states [ "commentEndDash" ] elif data in spaceCharacters : self . currentToken [ "data" ] += data elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "data" ] += data self . state = self . states [ "comment" ] return True def doctypeState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : self . state = self . states [ "beforeDoctypeName" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . stream . unget ( data ) self . state = self . states [ "beforeDoctypeName" ] return True def beforeDoctypeNameState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : pass elif data == u">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "name" ] = data self . state = self . states [ "doctypeName" ] return True def doctypeNameState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : self . currentToken [ "name" ] = self . currentToken [ "name" ] . translate ( asciiUpper2Lower ) self . state = self . states [ "afterDoctypeName" ] elif data == u">" : self . currentToken [ "name" ] = self . currentToken [ "name" ] . translate ( asciiUpper2Lower ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . currentToken [ "name" ] = self . currentToken [ "name" ] . translate ( asciiUpper2Lower ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "name" ] += data return True def afterDoctypeNameState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : pass elif data == u">" : self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . currentToken [ "correct" ] = False self . stream . unget ( data ) self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : if data in ( u"p" , u"P" ) : matched = True for expected in ( ( u"u" , u"U" ) , ( u"b" , u"B" ) , ( u"l" , u"L" ) , ( u"i" , u"I" ) , ( u"c" , u"C" ) ) : data = self . stream . char ( ) if data not in expected : matched = False break if matched : self . state = self . states [ "beforeDoctypePublicIdentifier" ] return True elif data in ( u"s" , u"S" ) : matched = True for expected in ( ( u"y" , u"Y" ) , ( u"s" , u"S" ) , ( u"t" , u"T" ) , ( u"e" , u"E" ) , ( u"m" , u"M" ) ) : data = self . stream . char ( ) if data not in expected : matched = False break if matched : self . state = self . states [ "beforeDoctypeSystemIdentifier" ] return True self . stream . unget ( data ) self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : , "datavars" : { "data" : data } } ) self . currentToken [ "correct" ] = False self . state = self . states [ "bogusDoctype" ] return True def beforeDoctypePublicIdentifierState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : pass elif data == "\"" : self . currentToken [ "publicId" ] = u"" self . state = self . states [ "doctypePublicIdentifierDoubleQuoted" ] elif data == "'" : self . currentToken [ "publicId" ] = u"" self . state = self . states [ "doctypePublicIdentifierSingleQuoted" ] elif data == ">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . state = self . states [ "bogusDoctype" ] return True def doctypePublicIdentifierDoubleQuotedState ( self ) : data = self . stream . char ( ) if data == "\"" : self . state = self . states [ "afterDoctypePublicIdentifier" ] elif data == ">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "publicId" ] += data return True def doctypePublicIdentifierSingleQuotedState ( self ) : data = self . stream . char ( ) if data == "'" : self . state = self . states [ "afterDoctypePublicIdentifier" ] elif data == ">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "publicId" ] += data return True def afterDoctypePublicIdentifierState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : pass elif data == "\"" : self . currentToken [ "systemId" ] = u"" self . state = self . states [ "doctypeSystemIdentifierDoubleQuoted" ] elif data == "'" : self . currentToken [ "systemId" ] = u"" self . state = self . states [ "doctypeSystemIdentifierSingleQuoted" ] elif data == ">" : self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . state = self . states [ "bogusDoctype" ] return True def beforeDoctypeSystemIdentifierState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : pass elif data == "\"" : self . currentToken [ "systemId" ] = u"" self . state = self . states [ "doctypeSystemIdentifierDoubleQuoted" ] elif data == "'" : self . currentToken [ "systemId" ] = u"" self . state = self . states [ "doctypeSystemIdentifierSingleQuoted" ] elif data == ">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . state = self . states [ "bogusDoctype" ] return True def doctypeSystemIdentifierDoubleQuotedState ( self ) : data = self . stream . char ( ) if data == "\"" : self . state = self . states [ "afterDoctypeSystemIdentifier" ] elif data == ">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "systemId" ] += data return True def doctypeSystemIdentifierSingleQuotedState ( self ) : data = self . stream . char ( ) if data == "'" : self . state = self . states [ "afterDoctypeSystemIdentifier" ] elif data == ">" : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . currentToken [ "systemId" ] += data return True def afterDoctypeSystemIdentifierState ( self ) : data = self . stream . char ( ) if data in spaceCharacters : pass elif data == ">" : self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . currentToken [ "correct" ] = False self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : self . tokenQueue . append ( { "type" : tokenTypes [ "ParseError" ] , "data" : } ) self . state = self . states [ "bogusDoctype" ] return True def bogusDoctypeState ( self ) : data = self . stream . char ( ) if data == u">" : self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] elif data is EOF : self . stream . unget ( data ) self . tokenQueue . append ( self . currentToken ) self . state = self . states [ "data" ] else : pass return True
