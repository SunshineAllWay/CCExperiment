""" Create SQL statements for QuerySets. The code in here encapsulates all of the SQL construction so that QuerySets themselves do not have to (and could be backed by things other than SQL databases). The abstraction barrier only works one way: this module has to know all about the internals of models in order to get the information it needs. """ import copy from django . utils . datastructures import SortedDict from django . utils . encoding import force_unicode from django . utils . tree import Node from django . db import connections , DEFAULT_DB_ALIAS from django . db . models import signals from django . db . models . expressions import ExpressionNode from django . db . models . fields import FieldDoesNotExist from django . db . models . query_utils import InvalidQuery from django . db . models . sql import aggregates as base_aggregates_module from django . db . models . sql . constants import * from django . db . models . sql . datastructures import EmptyResultSet , Empty , MultiJoin from django . db . models . sql . expressions import SQLEvaluator from django . db . models . sql . where import ( WhereNode , Constraint , EverythingNode , ExtraWhere , AND , OR ) from django . core . exceptions import FieldError __all__ = [ 'Query' , 'RawQuery' ] class RawQuery ( object ) : def __init__ ( self , sql , using , params = None ) : self . params = params or ( ) self . sql = sql self . using = using self . cursor = None self . low_mark , self . high_mark = 0 , None self . extra_select = { } self . aggregate_select = { } def clone ( self , using ) : return RawQuery ( self . sql , using , params = self . params ) def convert_values ( self , value , field , connection ) : return connection . ops . convert_values ( value , field ) def get_columns ( self ) : if self . cursor is None : self . _execute_query ( ) converter = connections [ self . using ] . introspection . table_name_converter return [ converter ( column_meta [ 0 ] ) for column_meta in self . cursor . description ] def __iter__ ( self ) : self . _execute_query ( ) if not connections [ self . using ] . features . can_use_chunked_reads : result = list ( self . cursor ) else : result = self . cursor return iter ( result ) def __repr__ ( self ) : return "<RawQuery: %r>" % ( self . sql % tuple ( self . params ) ) def _execute_query ( self ) : self . cursor = connections [ self . using ] . cursor ( ) self . cursor . execute ( self . sql , self . params ) class Query ( object ) : INNER = 'INNER JOIN' LOUTER = 'LEFT OUTER JOIN' alias_prefix = 'T' query_terms = QUERY_TERMS aggregates_module = base_aggregates_module compiler = 'SQLCompiler' def __init__ ( self , model , where = WhereNode ) : self . model = model self . alias_refcount = { } self . alias_map = { } self . table_map = { } self . join_map = { } self . rev_join_map = { } self . quote_cache = { } self . default_cols = True self . default_ordering = True self . standard_ordering = True self . ordering_aliases = [ ] self . select_fields = [ ] self . related_select_fields = [ ] self . dupe_avoidance = { } self . used_aliases = set ( ) self . filter_is_sticky = False self . included_inherited_models = { } self . select = [ ] self . tables = [ ] self . where = where ( ) self . where_class = where self . group_by = None self . having = where ( ) self . order_by = [ ] self . low_mark , self . high_mark = 0 , None self . distinct = False self . distinct_fields = [ ] self . select_for_update = False self . select_for_update_nowait = False self . select_related = False self . related_select_cols = [ ] self . aggregates = SortedDict ( ) self . aggregate_select_mask = None self . _aggregate_select_cache = None self . max_depth = 5 self . extra = SortedDict ( ) self . extra_select_mask = None self . _extra_select_cache = None self . extra_tables = ( ) self . extra_order_by = ( ) self . deferred_loading = ( set ( ) , True ) def __str__ ( self ) : sql , params = self . sql_with_params ( ) return sql % params def sql_with_params ( self ) : return self . get_compiler ( DEFAULT_DB_ALIAS ) . as_sql ( ) def __deepcopy__ ( self , memo ) : result = self . clone ( memo = memo ) memo [ id ( self ) ] = result return result def __getstate__ ( self ) : obj_dict = self . __dict__ . copy ( ) obj_dict [ 'related_select_fields' ] = [ ] obj_dict [ 'related_select_cols' ] = [ ] obj_dict [ 'select_fields' ] = [ f is not None and f . name or None for f in obj_dict [ 'select_fields' ] ] return obj_dict def __setstate__ ( self , obj_dict ) : opts = obj_dict [ 'model' ] . _meta obj_dict [ 'select_fields' ] = [ name is not None and opts . get_field ( name ) or None for name in obj_dict [ 'select_fields' ] ] self . __dict__ . update ( obj_dict ) def prepare ( self ) : return self def get_compiler ( self , using = None , connection = None ) : if using is None and connection is None : raise ValueError ( "Need either using or connection" ) if using : connection = connections [ using ] for alias , aggregate in self . aggregate_select . items ( ) : connection . ops . check_aggregate_support ( aggregate ) return connection . ops . compiler ( self . compiler ) ( self , connection , using ) def get_meta ( self ) : return self . model . _meta def clone ( self , klass = None , memo = None , ** kwargs ) : obj = Empty ( ) obj . __class__ = klass or self . __class__ obj . model = self . model obj . alias_refcount = self . alias_refcount . copy ( ) obj . alias_map = self . alias_map . copy ( ) obj . table_map = self . table_map . copy ( ) obj . join_map = self . join_map . copy ( ) obj . rev_join_map = self . rev_join_map . copy ( ) obj . quote_cache = { } obj . default_cols = self . default_cols obj . default_ordering = self . default_ordering obj . standard_ordering = self . standard_ordering obj . included_inherited_models = self . included_inherited_models . copy ( ) obj . ordering_aliases = [ ] obj . select_fields = self . select_fields [ : ] obj . related_select_fields = self . related_select_fields [ : ] obj . dupe_avoidance = self . dupe_avoidance . copy ( ) obj . select = self . select [ : ] obj . tables = self . tables [ : ] obj . where = copy . deepcopy ( self . where , memo = memo ) obj . where_class = self . where_class if self . group_by is None : obj . group_by = None else : obj . group_by = self . group_by [ : ] obj . having = copy . deepcopy ( self . having , memo = memo ) obj . order_by = self . order_by [ : ] obj . low_mark , obj . high_mark = self . low_mark , self . high_mark obj . distinct = self . distinct obj . distinct_fields = self . distinct_fields [ : ] obj . select_for_update = self . select_for_update obj . select_for_update_nowait = self . select_for_update_nowait obj . select_related = self . select_related obj . related_select_cols = [ ] obj . aggregates = copy . deepcopy ( self . aggregates , memo = memo ) if self . aggregate_select_mask is None : obj . aggregate_select_mask = None else : obj . aggregate_select_mask = self . aggregate_select_mask . copy ( ) obj . _aggregate_select_cache = None obj . max_depth = self . max_depth obj . extra = self . extra . copy ( ) if self . extra_select_mask is None : obj . extra_select_mask = None else : obj . extra_select_mask = self . extra_select_mask . copy ( ) if self . _extra_select_cache is None : obj . _extra_select_cache = None else : obj . _extra_select_cache = self . _extra_select_cache . copy ( ) obj . extra_tables = self . extra_tables obj . extra_order_by = self . extra_order_by obj . deferred_loading = copy . deepcopy ( self . deferred_loading , memo = memo ) if self . filter_is_sticky and self . used_aliases : obj . used_aliases = self . used_aliases . copy ( ) else : obj . used_aliases = set ( ) obj . filter_is_sticky = False obj . __dict__ . update ( kwargs ) if hasattr ( obj , '_setup_query' ) : obj . _setup_query ( ) return obj def convert_values ( self , value , field , connection ) : return connection . ops . convert_values ( value , field ) def resolve_aggregate ( self , value , aggregate , connection ) : if value is None : if aggregate . is_ordinal : return 0 return value elif aggregate . is_ordinal : return int ( value ) elif aggregate . is_computed : return float ( value ) else : return self . convert_values ( value , aggregate . field , connection ) def get_aggregation ( self , using ) : if not self . aggregate_select : return { } if self . group_by is not None : from django . db . models . sql . subqueries import AggregateQuery query = AggregateQuery ( self . model ) obj = self . clone ( ) for alias , aggregate in self . aggregate_select . items ( ) : if aggregate . is_summary : query . aggregate_select [ alias ] = aggregate del obj . aggregate_select [ alias ] try : query . add_subquery ( obj , using ) except EmptyResultSet : return dict ( ( alias , None ) for alias in query . aggregate_select ) else : query = self self . select = [ ] self . default_cols = False self . extra = { } self . remove_inherited_models ( ) query . clear_ordering ( True ) query . clear_limits ( ) query . select_for_update = False query . select_related = False query . related_select_cols = [ ] query . related_select_fields = [ ] result = query . get_compiler ( using ) . execute_sql ( SINGLE ) if result is None : result = [ None for q in query . aggregate_select . items ( ) ] return dict ( [ ( alias , self . resolve_aggregate ( val , aggregate , connection = connections [ using ] ) ) for ( alias , aggregate ) , val in zip ( query . aggregate_select . items ( ) , result ) ] ) def get_count ( self , using ) : obj = self . clone ( ) if len ( self . select ) > 1 or self . aggregate_select or ( self . distinct and self . distinct_fields ) : from django . db . models . sql . subqueries import AggregateQuery subquery = obj subquery . clear_ordering ( True ) subquery . clear_limits ( ) obj = AggregateQuery ( obj . model ) try : obj . add_subquery ( subquery , using = using ) except EmptyResultSet : return 0 obj . add_count_column ( ) number = obj . get_aggregation ( using = using ) [ None ] number = max ( 0 , number - self . low_mark ) if self . high_mark is not None : number = min ( number , self . high_mark - self . low_mark ) return number def has_results ( self , using ) : q = self . clone ( ) q . add_extra ( { 'a' : 1 } , None , None , None , None , None ) q . select = [ ] q . select_fields = [ ] q . default_cols = False q . select_related = False q . set_extra_mask ( ( 'a' , ) ) q . set_aggregate_mask ( ( ) ) q . clear_ordering ( True ) q . set_limits ( high = 1 ) compiler = q . get_compiler ( using = using ) return bool ( compiler . execute_sql ( SINGLE ) ) def combine ( self , rhs , connector ) : assert self . model == rhs . model , "Cannot combine queries on two different base models." assert self . can_filter ( ) , "Cannot combine queries once a slice has been taken." assert self . distinct == rhs . distinct , "Cannot combine a unique query with a non-unique query." assert self . distinct_fields == rhs . distinct_fields , "Cannot combine queries with different distinct fields." self . remove_inherited_models ( ) change_map = { } used = set ( ) conjunction = ( connector == AND ) first = True for alias in rhs . tables : if not rhs . alias_refcount [ alias ] : continue promote = ( rhs . alias_map [ alias ] [ JOIN_TYPE ] == self . LOUTER ) lhs , table , lhs_col , col = rhs . rev_join_map [ alias ] lhs = change_map . get ( lhs , lhs ) new_alias = self . join ( ( lhs , table , lhs_col , col ) , ( conjunction and not first ) , used , promote , not conjunction ) used . add ( new_alias ) change_map [ alias ] = new_alias first = False if not conjunction : l_tables = set ( self . tables ) r_tables = set ( rhs . tables ) for alias in change_map : if alias in r_tables : if rhs . alias_refcount [ alias ] : r_tables . remove ( alias ) r_tables . add ( change_map [ alias ] ) outer_tables = ( l_tables | r_tables ) - ( l_tables & r_tables ) for alias in outer_tables : if self . alias_refcount . get ( alias ) or rhs . alias_refcount . get ( alias ) : self . promote_alias ( alias , True ) if rhs . where : w = copy . deepcopy ( rhs . where ) w . relabel_aliases ( change_map ) if not self . where : self . where . add ( EverythingNode ( ) , AND ) elif self . where : w = self . where_class ( ) w . add ( EverythingNode ( ) , AND ) else : w = self . where_class ( ) self . where . add ( w , connector ) self . select = [ ] for col in rhs . select : if isinstance ( col , ( list , tuple ) ) : self . select . append ( ( change_map . get ( col [ 0 ] , col [ 0 ] ) , col [ 1 ] ) ) else : item = copy . deepcopy ( col ) item . relabel_aliases ( change_map ) self . select . append ( item ) self . select_fields = rhs . select_fields [ : ] if connector == OR : if self . extra and rhs . extra : raise ValueError ( "When merging querysets using 'or', you " ) self . extra . update ( rhs . extra ) extra_select_mask = set ( ) if self . extra_select_mask is not None : extra_select_mask . update ( self . extra_select_mask ) if rhs . extra_select_mask is not None : extra_select_mask . update ( rhs . extra_select_mask ) if extra_select_mask : self . set_extra_mask ( extra_select_mask ) self . extra_tables += rhs . extra_tables self . order_by = rhs . order_by and rhs . order_by [ : ] or self . order_by self . extra_order_by = rhs . extra_order_by or self . extra_order_by def deferred_to_data ( self , target , callback ) : field_names , defer = self . deferred_loading if not field_names : return orig_opts = self . model . _meta seen = { } if orig_opts . proxy : must_include = { orig_opts . proxy_for_model : set ( [ orig_opts . pk ] ) } else : must_include = { self . model : set ( [ orig_opts . pk ] ) } for field_name in field_names : parts = field_name . split ( LOOKUP_SEP ) cur_model = self . model opts = orig_opts for name in parts [ : - 1 ] : old_model = cur_model source = opts . get_field_by_name ( name ) [ 0 ] cur_model = opts . get_field_by_name ( name ) [ 0 ] . rel . to opts = cur_model . _meta must_include [ old_model ] . add ( source ) add_to_dict ( must_include , cur_model , opts . pk ) field , model , _ , _ = opts . get_field_by_name ( parts [ - 1 ] ) if model is None : model = cur_model add_to_dict ( seen , model , field ) if defer : workset = { } for model , values in seen . iteritems ( ) : for field , m in model . _meta . get_fields_with_model ( ) : if field in values : continue add_to_dict ( workset , m or model , field ) for model , values in must_include . iteritems ( ) : if model in workset : workset [ model ] . update ( values ) for model , values in workset . iteritems ( ) : callback ( target , model , values ) else : for model , values in must_include . iteritems ( ) : if model in seen : seen [ model ] . update ( values ) else : seen [ model ] = values for model in orig_opts . get_parent_list ( ) : if model not in seen : seen [ model ] = set ( ) for model , values in seen . iteritems ( ) : callback ( target , model , values ) def deferred_to_columns_cb ( self , target , model , fields ) : table = model . _meta . db_table if table not in target : target [ table ] = set ( ) for field in fields : target [ table ] . add ( field . column ) def table_alias ( self , table_name , create = False ) : current = self . table_map . get ( table_name ) if not create and current : alias = current [ 0 ] self . alias_refcount [ alias ] += 1 return alias , False if current : alias = '%s%d' % ( self . alias_prefix , len ( self . alias_map ) + 1 ) current . append ( alias ) else : alias = table_name self . table_map [ alias ] = [ alias ] self . alias_refcount [ alias ] = 1 self . tables . append ( alias ) return alias , True def ref_alias ( self , alias ) : self . alias_refcount [ alias ] += 1 def unref_alias ( self , alias , amount = 1 ) : self . alias_refcount [ alias ] -= amount def promote_alias ( self , alias , unconditional = False ) : if ( ( unconditional or self . alias_map [ alias ] [ NULLABLE ] ) and self . alias_map [ alias ] [ JOIN_TYPE ] != self . LOUTER ) : data = list ( self . alias_map [ alias ] ) data [ JOIN_TYPE ] = self . LOUTER self . alias_map [ alias ] = tuple ( data ) return True return False def promote_alias_chain ( self , chain , must_promote = False ) : for alias in chain : if self . promote_alias ( alias , must_promote ) : must_promote = True def reset_refcounts ( self , to_counts ) : for alias , cur_refcount in self . alias_refcount . copy ( ) . items ( ) : unref_amount = cur_refcount - to_counts . get ( alias , 0 ) self . unref_alias ( alias , unref_amount ) def promote_unused_aliases ( self , initial_refcounts , used_aliases ) : considered = { } for alias in self . tables : if alias not in used_aliases : continue if ( alias not in initial_refcounts or self . alias_refcount [ alias ] == initial_refcounts [ alias ] ) : parent = self . alias_map [ alias ] [ LHS_ALIAS ] must_promote = considered . get ( parent , False ) promoted = self . promote_alias ( alias , must_promote ) considered [ alias ] = must_promote or promoted def change_aliases ( self , change_map ) : assert set ( change_map . keys ( ) ) . intersection ( set ( change_map . values ( ) ) ) == set ( ) self . where . relabel_aliases ( change_map ) self . having . relabel_aliases ( change_map ) for columns in [ self . select , self . group_by or [ ] ] : for pos , col in enumerate ( columns ) : if isinstance ( col , ( list , tuple ) ) : old_alias = col [ 0 ] columns [ pos ] = ( change_map . get ( old_alias , old_alias ) , col [ 1 ] ) else : col . relabel_aliases ( change_map ) for mapping in [ self . aggregates ] : for key , col in mapping . items ( ) : if isinstance ( col , ( list , tuple ) ) : old_alias = col [ 0 ] mapping [ key ] = ( change_map . get ( old_alias , old_alias ) , col [ 1 ] ) else : col . relabel_aliases ( change_map ) for old_alias , new_alias in change_map . iteritems ( ) : alias_data = list ( self . alias_map [ old_alias ] ) alias_data [ RHS_ALIAS ] = new_alias t = self . rev_join_map [ old_alias ] data = list ( self . join_map [ t ] ) data [ data . index ( old_alias ) ] = new_alias self . join_map [ t ] = tuple ( data ) self . rev_join_map [ new_alias ] = t del self . rev_join_map [ old_alias ] self . alias_refcount [ new_alias ] = self . alias_refcount [ old_alias ] del self . alias_refcount [ old_alias ] self . alias_map [ new_alias ] = tuple ( alias_data ) del self . alias_map [ old_alias ] table_aliases = self . table_map [ alias_data [ TABLE_NAME ] ] for pos , alias in enumerate ( table_aliases ) : if alias == old_alias : table_aliases [ pos ] = new_alias break for pos , alias in enumerate ( self . tables ) : if alias == old_alias : self . tables [ pos ] = new_alias break for key , alias in self . included_inherited_models . items ( ) : if alias in change_map : self . included_inherited_models [ key ] = change_map [ alias ] for alias , data in self . alias_map . iteritems ( ) : lhs = data [ LHS_ALIAS ] if lhs in change_map : data = list ( data ) data [ LHS_ALIAS ] = change_map [ lhs ] self . alias_map [ alias ] = tuple ( data ) def bump_prefix ( self , exceptions = ( ) ) : current = ord ( self . alias_prefix ) assert current < ord ( 'Z' ) prefix = chr ( current + 1 ) self . alias_prefix = prefix change_map = { } for pos , alias in enumerate ( self . tables ) : if alias in exceptions : continue new_alias = '%s%d' % ( prefix , pos ) change_map [ alias ] = new_alias self . tables [ pos ] = new_alias self . change_aliases ( change_map ) def get_initial_alias ( self ) : if self . tables : alias = self . tables [ 0 ] self . ref_alias ( alias ) else : alias = self . join ( ( None , self . model . _meta . db_table , None , None ) ) return alias def count_active_tables ( self ) : return len ( [ 1 for count in self . alias_refcount . itervalues ( ) if count ] ) def join ( self , connection , always_create = False , exclusions = ( ) , promote = False , outer_if_first = False , nullable = False , reuse = None ) : lhs , table , lhs_col , col = connection if lhs in self . alias_map : lhs_table = self . alias_map [ lhs ] [ TABLE_NAME ] else : lhs_table = lhs if reuse and always_create and table in self . table_map : exclusions = set ( self . table_map [ table ] ) . difference ( reuse ) . union ( set ( exclusions ) ) always_create = False t_ident = ( lhs_table , table , lhs_col , col ) if not always_create : for alias in self . join_map . get ( t_ident , ( ) ) : if alias not in exclusions : if lhs_table and not self . alias_refcount [ self . alias_map [ alias ] [ LHS_ALIAS ] ] : continue if self . alias_map [ alias ] [ LHS_ALIAS ] != lhs : continue self . ref_alias ( alias ) if promote : self . promote_alias ( alias ) return alias alias , _ = self . table_alias ( table , True ) if not lhs : join_type = None elif promote or outer_if_first : join_type = self . LOUTER else : join_type = self . INNER join = ( table , alias , join_type , lhs , lhs_col , col , nullable ) self . alias_map [ alias ] = join if t_ident in self . join_map : self . join_map [ t_ident ] += ( alias , ) else : self . join_map [ t_ident ] = ( alias , ) self . rev_join_map [ alias ] = t_ident return alias def setup_inherited_models ( self ) : opts = self . model . _meta root_alias = self . tables [ 0 ] seen = { None : root_alias } proxied_model = get_proxied_model ( opts ) for field , model in opts . get_fields_with_model ( ) : if model not in seen : if model is proxied_model : seen [ model ] = root_alias else : link_field = opts . get_ancestor_link ( model ) seen [ model ] = self . join ( ( root_alias , model . _meta . db_table , link_field . column , model . _meta . pk . column ) ) self . included_inherited_models = seen def remove_inherited_models ( self ) : for key , alias in self . included_inherited_models . items ( ) : if key : self . unref_alias ( alias ) self . included_inherited_models = { } def need_force_having ( self , q_object ) : for child in q_object . children : if isinstance ( child , Node ) : if self . need_force_having ( child ) : return True else : if child [ 0 ] . split ( LOOKUP_SEP ) [ 0 ] in self . aggregates : return True return False def add_aggregate ( self , aggregate , model , alias , is_summary ) : opts = model . _meta field_list = aggregate . lookup . split ( LOOKUP_SEP ) if len ( field_list ) == 1 and aggregate . lookup in self . aggregates : field_name = field_list [ 0 ] col = field_name source = self . aggregates [ field_name ] if not is_summary : raise FieldError ( "Cannot compute %s('%s'): '%s' is an aggregate" % ( aggregate . name , field_name , field_name ) ) elif ( ( len ( field_list ) > 1 ) or ( field_list [ 0 ] not in [ i . name for i in opts . fields ] ) or self . group_by is None or not is_summary ) : field , source , opts , join_list , last , _ = self . setup_joins ( field_list , opts , self . get_initial_alias ( ) , False ) col , _ , join_list = self . trim_joins ( source , join_list , last , False ) for column_alias in join_list : self . promote_alias ( column_alias , unconditional = True ) col = ( join_list [ - 1 ] , col ) else : field_name = field_list [ 0 ] source = opts . get_field ( field_name ) col = field_name aggregate . add_to_query ( self , alias , col = col , source = source , is_summary = is_summary ) def add_filter ( self , filter_expr , connector = AND , negate = False , trim = False , can_reuse = None , process_extras = True , force_having = False ) : arg , value = filter_expr parts = arg . split ( LOOKUP_SEP ) if not parts : raise FieldError ( "Cannot parse keyword query %r" % arg ) lookup_type = 'exact' num_parts = len ( parts ) if ( len ( parts ) > 1 and parts [ - 1 ] in self . query_terms and arg not in self . aggregates ) : lookup_model = self . model for counter , field_name in enumerate ( parts ) : try : lookup_field = lookup_model . _meta . get_field ( field_name ) except FieldDoesNotExist : lookup_type = parts . pop ( ) break if ( counter + 1 ) < num_parts : try : lookup_model = lookup_field . rel . to except AttributeError : lookup_type = parts . pop ( ) break having_clause = False if value is None : if lookup_type != 'exact' : raise ValueError ( "Cannot use None as a query value" ) lookup_type = 'isnull' value = True elif callable ( value ) : value = value ( ) elif isinstance ( value , ExpressionNode ) : value = SQLEvaluator ( value , self ) having_clause = value . contains_aggregate for alias , aggregate in self . aggregates . items ( ) : if alias in ( parts [ 0 ] , LOOKUP_SEP . join ( parts ) ) : entry = self . where_class ( ) entry . add ( ( aggregate , lookup_type , value ) , AND ) if negate : entry . negate ( ) self . having . add ( entry , connector ) return opts = self . get_meta ( ) alias = self . get_initial_alias ( ) allow_many = trim or not negate try : field , target , opts , join_list , last , extra_filters = self . setup_joins ( parts , opts , alias , True , allow_many , allow_explicit_fk = True , can_reuse = can_reuse , negate = negate , process_extras = process_extras ) except MultiJoin , e : self . split_exclude ( filter_expr , LOOKUP_SEP . join ( parts [ : e . level ] ) , can_reuse ) return table_promote = False join_promote = False if ( lookup_type == 'isnull' and value is True and not negate and len ( join_list ) > 1 ) : self . promote_alias_chain ( join_list ) join_promote = True nonnull_comparison = ( lookup_type == 'isnull' and value is False ) col , alias , join_list = self . trim_joins ( target , join_list , last , trim , nonnull_comparison ) if connector == OR : join_it = iter ( join_list ) table_it = iter ( self . tables ) join_it . next ( ) , table_it . next ( ) unconditional = False for join in join_it : table = table_it . next ( ) unconditional = ( unconditional or self . alias_map [ join ] [ JOIN_TYPE ] == self . LOUTER ) if join == table and self . alias_refcount [ join ] > 1 : continue join_promote = join_promote or self . promote_alias ( join , unconditional ) if table != join : table_promote = self . promote_alias ( table ) break self . promote_alias_chain ( join_it , join_promote ) self . promote_alias_chain ( table_it , table_promote or join_promote ) if having_clause or force_having : if ( alias , col ) not in self . group_by : self . group_by . append ( ( alias , col ) ) self . having . add ( ( Constraint ( alias , col , field ) , lookup_type , value ) , connector ) else : self . where . add ( ( Constraint ( alias , col , field ) , lookup_type , value ) , connector ) if negate : self . promote_alias_chain ( join_list ) if lookup_type != 'isnull' : if len ( join_list ) > 1 : for alias in join_list : if self . alias_map [ alias ] [ JOIN_TYPE ] == self . LOUTER : j_col = self . alias_map [ alias ] [ RHS_JOIN_COL ] entry = self . where_class ( ) entry . add ( ( Constraint ( alias , j_col , None ) , 'isnull' , True ) , AND ) entry . negate ( ) self . where . add ( entry , AND ) break if not ( lookup_type == 'in' and not hasattr ( value , 'as_sql' ) and not hasattr ( value , '_as_sql' ) and not value ) and field . null : self . where . add ( ( Constraint ( alias , col , None ) , 'isnull' , False ) , AND ) if can_reuse is not None : can_reuse . update ( join_list ) if process_extras : for filter in extra_filters : self . add_filter ( filter , negate = negate , can_reuse = can_reuse , process_extras = False ) def add_q ( self , q_object , used_aliases = None , force_having = False ) : if used_aliases is None : used_aliases = self . used_aliases if hasattr ( q_object , 'add_to_query' ) : q_object . add_to_query ( self , used_aliases ) else : if self . where and q_object . connector != AND and len ( q_object ) > 1 : self . where . start_subtree ( AND ) subtree = True else : subtree = False connector = AND if q_object . connector == OR and not force_having : force_having = self . need_force_having ( q_object ) for child in q_object . children : if connector == OR : refcounts_before = self . alias_refcount . copy ( ) if force_having : self . having . start_subtree ( connector ) else : self . where . start_subtree ( connector ) if isinstance ( child , Node ) : self . add_q ( child , used_aliases , force_having = force_having ) else : self . add_filter ( child , connector , q_object . negated , can_reuse = used_aliases , force_having = force_having ) if force_having : self . having . end_subtree ( ) else : self . where . end_subtree ( ) if connector == OR : self . promote_unused_aliases ( refcounts_before , used_aliases ) connector = q_object . connector if q_object . negated : self . where . negate ( ) if subtree : self . where . end_subtree ( ) if self . filter_is_sticky : self . used_aliases = used_aliases def setup_joins ( self , names , opts , alias , dupe_multis , allow_many = True , allow_explicit_fk = False , can_reuse = None , negate = False , process_extras = True ) : joins = [ alias ] last = [ 0 ] dupe_set = set ( ) exclusions = set ( ) extra_filters = [ ] int_alias = None for pos , name in enumerate ( names ) : if int_alias is not None : exclusions . add ( int_alias ) exclusions . add ( alias ) last . append ( len ( joins ) ) if name == 'pk' : name = opts . pk . name try : field , model , direct , m2m = opts . get_field_by_name ( name ) except FieldDoesNotExist : for f in opts . fields : if allow_explicit_fk and name == f . attname : field , model , direct , m2m = opts . get_field_by_name ( f . name ) break else : names = opts . get_all_field_names ( ) + self . aggregate_select . keys ( ) raise FieldError ( "Cannot resolve keyword %r into field. " % ( name , ", " . join ( names ) ) ) if not allow_many and ( m2m or not direct ) : for alias in joins : self . unref_alias ( alias ) raise MultiJoin ( pos + 1 ) if model : proxied_model = get_proxied_model ( opts ) for int_model in opts . get_base_chain ( model ) : if int_model is proxied_model : opts = int_model . _meta else : lhs_col = opts . parents [ int_model ] . column dedupe = lhs_col in opts . duplicate_targets if dedupe : exclusions . update ( self . dupe_avoidance . get ( ( id ( opts ) , lhs_col ) , ( ) ) ) dupe_set . add ( ( opts , lhs_col ) ) opts = int_model . _meta alias = self . join ( ( alias , opts . db_table , lhs_col , opts . pk . column ) , exclusions = exclusions ) joins . append ( alias ) exclusions . add ( alias ) for ( dupe_opts , dupe_col ) in dupe_set : self . update_dupe_avoidance ( dupe_opts , dupe_col , alias ) cached_data = opts . _join_cache . get ( name ) orig_opts = opts dupe_col = direct and field . column or field . field . column dedupe = dupe_col in opts . duplicate_targets if dupe_set or dedupe : if dedupe : dupe_set . add ( ( opts , dupe_col ) ) exclusions . update ( self . dupe_avoidance . get ( ( id ( opts ) , dupe_col ) , ( ) ) ) if process_extras and hasattr ( field , 'extra_filters' ) : extra_filters . extend ( field . extra_filters ( names , pos , negate ) ) if direct : if m2m : if cached_data : ( table1 , from_col1 , to_col1 , table2 , from_col2 , to_col2 , opts , target ) = cached_data else : table1 = field . m2m_db_table ( ) from_col1 = opts . get_field_by_name ( field . m2m_target_field_name ( ) ) [ 0 ] . column to_col1 = field . m2m_column_name ( ) opts = field . rel . to . _meta table2 = opts . db_table from_col2 = field . m2m_reverse_name ( ) to_col2 = opts . get_field_by_name ( field . m2m_reverse_target_field_name ( ) ) [ 0 ] . column target = opts . pk orig_opts . _join_cache [ name ] = ( table1 , from_col1 , to_col1 , table2 , from_col2 , to_col2 , opts , target ) int_alias = self . join ( ( alias , table1 , from_col1 , to_col1 ) , dupe_multis , exclusions , nullable = True , reuse = can_reuse ) if int_alias == table2 and from_col2 == to_col2 : joins . append ( int_alias ) alias = int_alias else : alias = self . join ( ( int_alias , table2 , from_col2 , to_col2 ) , dupe_multis , exclusions , nullable = True , reuse = can_reuse ) joins . extend ( [ int_alias , alias ] ) elif field . rel : if cached_data : ( table , from_col , to_col , opts , target ) = cached_data else : opts = field . rel . to . _meta target = field . rel . get_related_field ( ) table = opts . db_table from_col = field . column to_col = target . column orig_opts . _join_cache [ name ] = ( table , from_col , to_col , opts , target ) alias = self . join ( ( alias , table , from_col , to_col ) , exclusions = exclusions , nullable = field . null ) joins . append ( alias ) else : target = field break else : orig_field = field field = field . field if m2m : if cached_data : ( table1 , from_col1 , to_col1 , table2 , from_col2 , to_col2 , opts , target ) = cached_data else : table1 = field . m2m_db_table ( ) from_col1 = opts . get_field_by_name ( field . m2m_reverse_target_field_name ( ) ) [ 0 ] . column to_col1 = field . m2m_reverse_name ( ) opts = orig_field . opts table2 = opts . db_table from_col2 = field . m2m_column_name ( ) to_col2 = opts . get_field_by_name ( field . m2m_target_field_name ( ) ) [ 0 ] . column target = opts . pk orig_opts . _join_cache [ name ] = ( table1 , from_col1 , to_col1 , table2 , from_col2 , to_col2 , opts , target ) int_alias = self . join ( ( alias , table1 , from_col1 , to_col1 ) , dupe_multis , exclusions , nullable = True , reuse = can_reuse ) alias = self . join ( ( int_alias , table2 , from_col2 , to_col2 ) , dupe_multis , exclusions , nullable = True , reuse = can_reuse ) joins . extend ( [ int_alias , alias ] ) else : if cached_data : ( table , from_col , to_col , opts , target ) = cached_data else : local_field = opts . get_field_by_name ( field . rel . field_name ) [ 0 ] opts = orig_field . opts table = opts . db_table from_col = local_field . column to_col = field . column if orig_field . model is local_field . model : target = opts . get_field_by_name ( field . rel . field_name ) [ 0 ] else : target = opts . pk orig_opts . _join_cache [ name ] = ( table , from_col , to_col , opts , target ) alias = self . join ( ( alias , table , from_col , to_col ) , dupe_multis , exclusions , nullable = True , reuse = can_reuse ) joins . append ( alias ) for ( dupe_opts , dupe_col ) in dupe_set : if int_alias is None : to_avoid = alias else : to_avoid = int_alias self . update_dupe_avoidance ( dupe_opts , dupe_col , to_avoid ) if pos != len ( names ) - 1 : if pos == len ( names ) - 2 : raise FieldError ( "Join on field %r not permitted. Did you misspell %r for the lookup type?" % ( name , names [ pos + 1 ] ) ) else : raise FieldError ( "Join on field %r not permitted." % name ) return field , target , opts , joins , last , extra_filters def trim_joins ( self , target , join_list , last , trim , nonnull_check = False ) : final = len ( join_list ) penultimate = last . pop ( ) if penultimate == final : penultimate = last . pop ( ) if trim and final > 1 : extra = join_list [ penultimate : ] join_list = join_list [ : penultimate ] final = penultimate penultimate = last . pop ( ) col = self . alias_map [ extra [ 0 ] ] [ LHS_JOIN_COL ] for alias in extra : self . unref_alias ( alias ) else : col = target . column alias = join_list [ - 1 ] while final > 1 : join = self . alias_map [ alias ] if ( col != join [ RHS_JOIN_COL ] or join [ JOIN_TYPE ] != self . INNER or nonnull_check ) : break self . unref_alias ( alias ) alias = join [ LHS_ALIAS ] col = join [ LHS_JOIN_COL ] join_list . pop ( ) final -= 1 if final == penultimate : penultimate = last . pop ( ) return col , alias , join_list def update_dupe_avoidance ( self , opts , col , alias ) : ident = id ( opts ) for name in opts . duplicate_targets [ col ] : try : self . dupe_avoidance [ ident , name ] . add ( alias ) except KeyError : self . dupe_avoidance [ ident , name ] = set ( [ alias ] ) def split_exclude ( self , filter_expr , prefix , can_reuse ) : query = Query ( self . model ) query . add_filter ( filter_expr , can_reuse = can_reuse ) query . bump_prefix ( ) query . clear_ordering ( True ) query . set_start ( prefix ) alias , col = query . select [ 0 ] query . where . add ( ( Constraint ( alias , col , None ) , 'isnull' , False ) , AND ) self . add_filter ( ( '%s__in' % prefix , query ) , negate = True , trim = True , can_reuse = can_reuse ) active_positions = [ pos for ( pos , count ) in enumerate ( query . alias_refcount . itervalues ( ) ) if count ] if active_positions [ - 1 ] > 1 : self . add_filter ( ( '%s__isnull' % prefix , False ) , negate = True , trim = True , can_reuse = can_reuse ) def set_limits ( self , low = None , high = None ) : if high is not None : if self . high_mark is not None : self . high_mark = min ( self . high_mark , self . low_mark + high ) else : self . high_mark = self . low_mark + high if low is not None : if self . high_mark is not None : self . low_mark = min ( self . high_mark , self . low_mark + low ) else : self . low_mark = self . low_mark + low def clear_limits ( self ) : self . low_mark , self . high_mark = 0 , None def can_filter ( self ) : return not self . low_mark and self . high_mark is None def clear_select_fields ( self ) : self . select = [ ] self . select_fields = [ ] def add_distinct_fields ( self , * field_names ) : self . distinct_fields = field_names self . distinct = True def add_fields ( self , field_names , allow_m2m = True ) : alias = self . get_initial_alias ( ) opts = self . get_meta ( ) try : for name in field_names : field , target , u2 , joins , u3 , u4 = self . setup_joins ( name . split ( LOOKUP_SEP ) , opts , alias , False , allow_m2m , True ) final_alias = joins [ - 1 ] col = target . column if len ( joins ) > 1 : join = self . alias_map [ final_alias ] if col == join [ RHS_JOIN_COL ] : self . unref_alias ( final_alias ) final_alias = join [ LHS_ALIAS ] col = join [ LHS_JOIN_COL ] joins = joins [ : - 1 ] self . promote_alias_chain ( joins [ 1 : ] ) self . select . append ( ( final_alias , col ) ) self . select_fields . append ( field ) except MultiJoin : raise FieldError ( "Invalid field name: '%s'" % name ) except FieldError : names = opts . get_all_field_names ( ) + self . extra . keys ( ) + self . aggregate_select . keys ( ) names . sort ( ) raise FieldError ( "Cannot resolve keyword %r into field. " % ( name , ", " . join ( names ) ) ) self . remove_inherited_models ( ) def add_ordering ( self , * ordering ) : errors = [ ] for item in ordering : if not ORDER_PATTERN . match ( item ) : errors . append ( item ) if errors : raise FieldError ( 'Invalid order_by arguments: %s' % errors ) if ordering : self . order_by . extend ( ordering ) else : self . default_ordering = False def clear_ordering ( self , force_empty = False ) : self . order_by = [ ] self . extra_order_by = ( ) if force_empty : self . default_ordering = False def set_group_by ( self ) : self . group_by = [ ] for sel in self . select : self . group_by . append ( sel ) def add_count_column ( self ) : if not self . distinct : if not self . select : count = self . aggregates_module . Count ( '*' , is_summary = True ) else : assert len ( self . select ) == 1 , "Cannot add count col with multiple cols in 'select': %r" % self . select count = self . aggregates_module . Count ( self . select [ 0 ] ) else : opts = self . model . _meta if not self . select : count = self . aggregates_module . Count ( ( self . join ( ( None , opts . db_table , None , None ) ) , opts . pk . column ) , is_summary = True , distinct = True ) else : assert len ( self . select ) == 1 , "Cannot add count col with multiple cols in 'select'." count = self . aggregates_module . Count ( self . select [ 0 ] , distinct = True ) self . distinct = False self . aggregates = { None : count } self . set_aggregate_mask ( None ) self . group_by = None def add_select_related ( self , fields ) : field_dict = { } for field in fields : d = field_dict for part in field . split ( LOOKUP_SEP ) : d = d . setdefault ( part , { } ) self . select_related = field_dict self . related_select_cols = [ ] self . related_select_fields = [ ] def add_extra ( self , select , select_params , where , params , tables , order_by ) : if select : select_pairs = SortedDict ( ) if select_params : param_iter = iter ( select_params ) else : param_iter = iter ( [ ] ) for name , entry in select . items ( ) : entry = force_unicode ( entry ) entry_params = [ ] pos = entry . find ( "%s" ) while pos != - 1 : entry_params . append ( param_iter . next ( ) ) pos = entry . find ( "%s" , pos + 2 ) select_pairs [ name ] = ( entry , entry_params ) self . extra . update ( select_pairs ) if where or params : self . where . add ( ExtraWhere ( where , params ) , AND ) if tables : self . extra_tables += tuple ( tables ) if order_by : self . extra_order_by = order_by def clear_deferred_loading ( self ) : self . deferred_loading = ( set ( ) , True ) def add_deferred_loading ( self , field_names ) : existing , defer = self . deferred_loading if defer : self . deferred_loading = existing . union ( field_names ) , True else : self . deferred_loading = existing . difference ( field_names ) , False def add_immediate_loading ( self , field_names ) : existing , defer = self . deferred_loading field_names = set ( field_names ) if 'pk' in field_names : field_names . remove ( 'pk' ) field_names . add ( self . model . _meta . pk . name ) if defer : self . deferred_loading = field_names . difference ( existing ) , False else : self . deferred_loading = field_names , False def get_loaded_field_names ( self ) : collection = { } self . deferred_to_data ( collection , self . get_loaded_field_names_cb ) return collection def get_loaded_field_names_cb ( self , target , model , fields ) : target [ model ] = set ( [ f . name for f in fields ] ) def set_aggregate_mask ( self , names ) : if names is None : self . aggregate_select_mask = None else : self . aggregate_select_mask = set ( names ) self . _aggregate_select_cache = None def set_extra_mask ( self , names ) : if names is None : self . extra_select_mask = None else : self . extra_select_mask = set ( names ) self . _extra_select_cache = None def _aggregate_select ( self ) : if self . _aggregate_select_cache is not None : return self . _aggregate_select_cache elif self . aggregate_select_mask is not None : self . _aggregate_select_cache = SortedDict ( [ ( k , v ) for k , v in self . aggregates . items ( ) if k in self . aggregate_select_mask ] ) return self . _aggregate_select_cache else : return self . aggregates aggregate_select = property ( _aggregate_select ) def _extra_select ( self ) : if self . _extra_select_cache is not None : return self . _extra_select_cache elif self . extra_select_mask is not None : self . _extra_select_cache = SortedDict ( [ ( k , v ) for k , v in self . extra . items ( ) if k in self . extra_select_mask ] ) return self . _extra_select_cache else : return self . extra extra_select = property ( _extra_select ) def set_start ( self , start ) : opts = self . model . _meta alias = self . get_initial_alias ( ) field , col , opts , joins , last , extra = self . setup_joins ( start . split ( LOOKUP_SEP ) , opts , alias , False ) select_col = self . alias_map [ joins [ 1 ] ] [ LHS_JOIN_COL ] select_alias = alias for alias in joins : self . unref_alias ( alias ) for alias in joins [ 1 : ] : join_info = self . alias_map [ alias ] if ( join_info [ LHS_JOIN_COL ] != select_col or join_info [ JOIN_TYPE ] != self . INNER ) : break self . unref_alias ( select_alias ) select_alias = join_info [ RHS_ALIAS ] select_col = join_info [ RHS_JOIN_COL ] self . select = [ ( select_alias , select_col ) ] self . remove_inherited_models ( ) def get_order_dir ( field , default = 'ASC' ) : dirn = ORDER_DIR [ default ] if field [ 0 ] == '-' : return field [ 1 : ] , dirn [ 1 ] return field , dirn [ 0 ] def setup_join_cache ( sender , ** kwargs ) : sender . _meta . _join_cache = { } signals . class_prepared . connect ( setup_join_cache ) def add_to_dict ( data , key , value ) : if key in data : data [ key ] . add ( value ) else : data [ key ] = set ( [ value ] ) def get_proxied_model ( opts ) : int_opts = opts proxied_model = None while int_opts . proxy : proxied_model = int_opts . proxy_for_model int_opts = proxied_model . _meta return proxied_model
