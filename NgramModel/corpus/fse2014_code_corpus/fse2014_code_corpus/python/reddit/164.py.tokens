from __future__ import with_statement import new , sys , sha from datetime import datetime from copy import copy , deepcopy import operators import tdb_sql as tdb import sorts from . . utils import iters , Results , tup , to36 , Storage , timefromnow from . . utils import iters , Results , tup , to36 , Storage , thing_utils , timefromnow from r2 . config import cache from r2 . lib . cache import sgm from r2 . lib . log import log_text from pylons import g class NotFound ( Exception ) : pass CreationError = tdb . CreationError thing_types = { } rel_types = { } def begin ( ) : tdb . transactions . begin ( ) def commit ( ) : tdb . transactions . commit ( ) def rollback ( ) : tdb . transactions . rollback ( ) def obj_id ( things ) : return tuple ( t if isinstance ( t , ( int , long ) ) else t . _id for t in things ) def thing_prefix ( cls_name , id = None ) : p = cls_name + '_' if id : p += str ( id ) return p class SafeSetAttr : def __init__ ( self , cls ) : self . cls = cls def __enter__ ( self ) : self . cls . __safe__ = True def __exit__ ( self , type , value , tb ) : self . cls . __safe__ = False class DataThing ( object ) : _base_props = ( ) _int_props = ( ) _data_int_props = ( ) _int_prop_suffix = None _defaults = { } _essentials = ( ) c = operators . Slots ( ) __safe__ = False _asked_for_data = False def __init__ ( self ) : safe_set_attr = SafeSetAttr ( self ) with safe_set_attr : self . safe_set_attr = safe_set_attr self . _dirties = { } self . _t = { } self . _created = False self . _loaded = True self . _asked_for_data = True def __setattr__ ( self , attr , val , make_dirty = True ) : if attr . startswith ( '__' ) or self . __safe__ : object . __setattr__ ( self , attr , val ) return if attr . startswith ( '_' ) : if make_dirty and hasattr ( self , attr ) : old_val = getattr ( self , attr ) object . __setattr__ ( self , attr , val ) if not attr in self . _base_props : return else : old_val = self . _t . get ( attr , self . _defaults . get ( attr ) ) self . _t [ attr ] = val if make_dirty and val != old_val : self . _dirties [ attr ] = ( old_val , val ) def __getattr__ ( self , attr ) : if attr . startswith ( '__' ) : raise AttributeError , attr if not ( attr . startswith ( '_' ) or self . _asked_for_data or getattr ( self , "_nodb" , False ) ) : msg = ( "getattr(%r) called on %r, " + ) % ( attr , self ) raise ValueError ( msg ) try : if hasattr ( self , '_t' ) : rv = self . _t [ attr ] return rv else : raise AttributeError , attr except KeyError : try : return getattr ( self , '_defaults' ) [ attr ] except KeyError : try : _id = object . __getattribute__ ( self , "_id" ) except AttributeError : _id = "???" try : cl = object . __getattribute__ ( self , "__class__" ) . __name__ except AttributeError : cl = "???" if self . _loaded : nl = "it IS loaded" else : nl = "it is NOT loaded" try : id_str = "%d" % _id except TypeError : id_str = "%r" % _id descr = '%s(%s).%s' % ( cl , id_str , attr ) try : essentials = object . __getattribute__ ( self , "_essentials" ) except AttributeError : print "%s has no _essentials" % descr essentials = ( ) if isinstance ( essentials , str ) : print "Some dumbass forgot a comma." essentials = essentials , deleted = object . __getattribute__ ( self , "_deleted" ) if deleted : nl += " and IS deleted." else : nl += " and is NOT deleted." if attr in essentials and not deleted : log_text ( "essentials-bandaid-reload" , % ( descr , nl ) , ) self . _load ( ) try : return self . _t [ attr ] except KeyError : log_text ( "essentials-bandaid-failed" , % descr , "error" ) raise AttributeError , '%s not found; %s' % ( descr , nl ) def _cache_key ( self ) : return thing_prefix ( self . __class__ . __name__ , self . _id ) def _other_self ( self ) : l = cache . get ( self . _cache_key ( ) , allow_local = False ) if l and l . _id != self . _id : g . log . error ( "thing.py: Doppleganger on read: got %s for %s" , ( l , self ) ) cache . delete ( self . _cache_key ( ) ) return return l def _cache_myself ( self ) : ck = self . _cache_key ( ) cache . set ( ck , self ) def _sync_latest ( self ) : other_self = self . _other_self ( ) if not other_self : return self . _dirty for prop in self . _base_props : self . __setattr__ ( prop , getattr ( other_self , prop ) , False ) if other_self . _loaded : self . _t = other_self . _t old_dirties = self . _dirties self . _dirties = { } for k , ( old_val , new_val ) in old_dirties . iteritems ( ) : setattr ( self , k , new_val ) return self . _dirty def _commit ( self , keys = None ) : if not self . _created : self . _create ( ) with g . make_lock ( 'commit_' + self . _fullname ) : if not self . _sync_latest ( ) : self . _cache_myself ( ) return if keys : keys = tup ( keys ) to_set = dict ( ( k , self . _dirties [ k ] [ 1 ] ) for k in keys if self . _dirties . has_key ( k ) ) else : to_set = dict ( ( k , v [ 1 ] ) for k , v in self . _dirties . iteritems ( ) ) data_props = { } thing_props = { } for k , v in to_set . iteritems ( ) : if k . startswith ( '_' ) : thing_props [ k [ 1 : ] ] = v else : data_props [ k ] = v if data_props : self . _set_data ( self . _type_id , self . _id , ** data_props ) if thing_props : self . _set_props ( self . _type_id , self . _id , ** thing_props ) if keys : for k in keys : if self . _dirties . has_key ( k ) : del self . _dirties [ k ] else : self . _dirties . clear ( ) self . _cache_myself ( ) @ classmethod def _load_multi ( cls , need , check_essentials = True ) : need = tup ( need ) need_ids = [ n . _id for n in need ] datas = cls . _get_data ( cls . _type_id , need_ids ) to_save = { } try : essentials = object . __getattribute__ ( cls , "_essentials" ) except AttributeError : essentials = ( ) for i in need : i . _t . update ( datas . get ( i . _id , i . _t ) ) i . _loaded = True for essential in essentials : if essential not in i . _t : if check_essentials : raise AttributeError ( "Refusing to cache %s; it's missing %s" % ( i . _fullname , essential ) ) else : print "Warning: %s is missing %s" % ( i . _fullname , essential ) i . _asked_for_data = True to_save [ i . _id ] = i prefix = thing_prefix ( cls . __name__ ) cache . set_multi ( to_save , prefix = prefix ) def _load ( self , check_essentials = True ) : self . _load_multi ( self , check_essentials ) def _safe_load ( self ) : if not self . _loaded : self . _load ( ) def _incr ( self , prop , amt = 1 ) : if self . _dirty : raise ValueError , "cannot incr dirty thing" if prop not in self . _int_props : if ( prop in self . _data_int_props or self . _int_prop_suffix and prop . endswith ( self . _int_prop_suffix ) ) : if not self . _loaded : self . _load ( ) else : msg = ( "cannot incr non int prop %r on %r -- it's not in %r or %r" % ( prop , self , self . _int_props , self . _data_int_props ) ) raise ValueError , msg with g . make_lock ( 'commit_' + self . _fullname ) : self . _sync_latest ( ) old_val = getattr ( self , prop ) if self . _defaults . has_key ( prop ) and self . _defaults [ prop ] == old_val : setattr ( self , prop , old_val + amt ) self . _commit ( prop ) else : self . __setattr__ ( prop , old_val + amt , False ) if prop . startswith ( '_' ) : tdb . incr_thing_prop ( self . _type_id , self . _id , prop [ 1 : ] , amt ) else : self . _incr_data ( self . _type_id , self . _id , prop , amt ) self . _cache_myself ( ) @ property def _id36 ( self ) : return to36 ( self . _id ) @ property def _fullname ( self ) : return self . _type_prefix + to36 ( self . _type_id ) + '_' + to36 ( self . _id ) @ classmethod def _byID ( cls , ids , data = False , return_dict = True , extra_props = None , stale = False , check_essentials = True ) : ids , single = tup ( ids , True ) prefix = thing_prefix ( cls . __name__ ) if not all ( x <= tdb . MAX_THING_ID for x in ids ) : raise NotFound ( 'huge thing_id in %r' % ids ) def items_db ( ids ) : items = cls . _get_item ( cls . _type_id , ids ) for i in items . keys ( ) : items [ i ] = cls . _build ( i , items [ i ] ) return items bases = sgm ( cache , ids , items_db , prefix , stale = stale ) for i in ids : if i not in bases : missing = [ i for i in ids if i not in bases ] raise NotFound , '%s %s' % ( cls . __name__ , missing ) if bases [ i ] and bases [ i ] . _id != i : g . log . error ( "thing.py: Doppleganger on byID: %s got %s for %s" % ( cls . __name__ , bases [ i ] . _id , i ) ) bases [ i ] = items_db ( [ i ] ) . values ( ) [ 0 ] bases [ i ] . _cache_myself ( ) if data : need = [ ] for v in bases . itervalues ( ) : v . _asked_for_data = True if not v . _loaded : need . append ( v ) if need : cls . _load_multi ( need , check_essentials ) if extra_props : for _id , props in extra_props . iteritems ( ) : for k , v in props . iteritems ( ) : bases [ _id ] . __setattr__ ( k , v , False ) if single : return bases [ ids [ 0 ] ] elif return_dict : return bases else : return filter ( None , ( bases . get ( i ) for i in ids ) ) @ classmethod def _byID36 ( cls , id36s , return_dict = True , ** kw ) : id36s , single = tup ( id36s , True ) ids = [ int ( x , 36 ) for x in id36s ] things = cls . _byID ( ids , return_dict = True , ** kw ) if single : return things . values ( ) [ 0 ] elif return_dict : return things else : return things . values ( ) @ classmethod def _by_fullname ( cls , names , return_dict = True , ** kw ) : names , single = tup ( names , True ) table = { } lookup = { } for fullname in names : try : real_type , thing_id = fullname . split ( '_' ) if real_type [ 0 ] == 't' : type_dict = thing_types elif real_type [ 0 ] == 'r' : type_dict = rel_types real_type = type_dict [ int ( real_type [ 1 : ] , 36 ) ] thing_id = int ( thing_id , 36 ) lookup [ fullname ] = ( real_type , thing_id ) table . setdefault ( real_type , [ ] ) . append ( thing_id ) except ValueError : if single : raise NotFound identified = { } for real_type , thing_ids in table . iteritems ( ) : i = real_type . _byID ( thing_ids , ** kw ) identified [ real_type ] = i res = [ ] for fullname in names : if lookup . has_key ( fullname ) : real_type , thing_id = lookup [ fullname ] res . append ( ( fullname , identified . get ( real_type , { } ) . get ( thing_id ) ) ) if single : return res [ 0 ] [ 1 ] elif return_dict : return dict ( res ) else : return [ x for i , x in res ] @ property def _dirty ( self ) : return bool ( len ( self . _dirties ) ) @ classmethod def _query ( cls , * a , ** kw ) : raise NotImplementedError ( ) @ classmethod def _build ( * a , ** kw ) : raise NotImplementedError ( ) def _get_data ( * a , ** kw ) : raise NotImplementedError ( ) def _set_data ( * a , ** kw ) : raise NotImplementedError ( ) def _incr_data ( * a , ** kw ) : raise NotImplementedError ( ) def _get_item ( * a , ** kw ) : raise NotImplementedError def _create ( self ) : base_props = ( getattr ( self , prop ) for prop in self . _base_props ) self . _id = self . _make_fn ( self . _type_id , * base_props ) self . _created = True class ThingMeta ( type ) : def __init__ ( cls , name , bases , dct ) : if name == 'Thing' or hasattr ( cls , '_nodb' ) and cls . _nodb : return cls . _type_name = name . lower ( ) try : cls . _type_id = tdb . types_name [ cls . _type_name ] . type_id except KeyError : raise KeyError , 'is the thing database %s defined?' % name global thing_types thing_types [ cls . _type_id ] = cls super ( ThingMeta , cls ) . __init__ ( name , bases , dct ) def __repr__ ( cls ) : return '<thing: %s>' % cls . _type_name class Thing ( DataThing ) : __metaclass__ = ThingMeta _base_props = ( '_ups' , '_downs' , '_date' , '_deleted' , '_spam' ) _int_props = ( '_ups' , '_downs' ) _make_fn = staticmethod ( tdb . make_thing ) _set_props = staticmethod ( tdb . set_thing_props ) _get_data = staticmethod ( tdb . get_thing_data ) _set_data = staticmethod ( tdb . set_thing_data ) _get_item = staticmethod ( tdb . get_thing ) _incr_data = staticmethod ( tdb . incr_thing_data ) _type_prefix = 't' def __init__ ( self , ups = 0 , downs = 0 , date = None , deleted = False , spam = False , id = None , ** attrs ) : DataThing . __init__ ( self ) with self . safe_set_attr : if id : self . _id = id self . _created = True self . _loaded = False if not date : date = datetime . now ( g . tz ) self . _ups = ups self . _downs = downs self . _date = date self . _deleted = deleted self . _spam = spam for k , v in attrs . iteritems ( ) : self . __setattr__ ( k , v , not self . _created ) def __repr__ ( self ) : return '<%s %s>' % ( self . __class__ . __name__ , self . _id if self . _created else '[unsaved]' ) def _set_id ( self , thing_id ) : if not self . _created : with self . safe_set_attr : self . _base_props += ( '_thing_id' , ) self . _thing_id = thing_id @ property def _hot ( self ) : return sorts . hot ( self . _ups , self . _downs , self . _date ) @ property def _score ( self ) : return sorts . score ( self . _ups , self . _downs ) @ property def _controversy ( self ) : return sorts . controversy ( self . _ups , self . _downs ) @ property def _confidence ( self ) : return sorts . confidence ( self . _ups , self . _downs ) @ classmethod def _build ( cls , id , bases ) : return cls ( bases . ups , bases . downs , bases . date , bases . deleted , bases . spam , id ) @ classmethod def _query ( cls , * all_rules , ** kw ) : need_deleted = True need_spam = True rules = [ ] optimize_rules = kw . pop ( 'optimize_rules' , False ) for r in all_rules : if not isinstance ( r , operators . op ) : continue if r . lval_name == '_deleted' : need_deleted = False if optimize_rules and r . rval == ( True , False ) : continue elif r . lval_name == '_spam' : need_spam = False if optimize_rules and r . rval == ( True , False ) : continue rules . append ( r ) if need_deleted : rules . append ( cls . c . _deleted == False ) if need_spam : rules . append ( cls . c . _spam == False ) return Things ( cls , * rules , ** kw ) def __getattr__ ( self , attr ) : return DataThing . __getattr__ ( self , attr ) class RelationMeta ( type ) : def __init__ ( cls , name , bases , dct ) : if name == 'RelationCls' : return cls . _type_name = name . lower ( ) try : cls . _type_id = tdb . rel_types_name [ cls . _type_name ] . type_id except KeyError : raise KeyError , 'is the relationship database %s defined?' % name global rel_types rel_types [ cls . _type_id ] = cls super ( RelationMeta , cls ) . __init__ ( name , bases , dct ) def __repr__ ( cls ) : return '<relation: %s>' % cls . _type_name def Relation ( type1 , type2 , denorm1 = None , denorm2 = None ) : class RelationCls ( DataThing ) : __metaclass__ = RelationMeta if not ( issubclass ( type1 , Thing ) and issubclass ( type2 , Thing ) ) : raise TypeError ( 'Relation types must be subclass of %s' % Thing ) _type1 = type1 _type2 = type2 _base_props = ( '_thing1_id' , '_thing2_id' , '_name' , '_date' ) _make_fn = staticmethod ( tdb . make_relation ) _set_props = staticmethod ( tdb . set_rel_props ) _get_data = staticmethod ( tdb . get_rel_data ) _set_data = staticmethod ( tdb . set_rel_data ) _get_item = staticmethod ( tdb . get_rel ) _incr_data = staticmethod ( tdb . incr_rel_data ) _type_prefix = Relation . _type_prefix _eagerly_loaded_data = False @ classmethod def _byID_rel ( cls , ids , data = False , return_dict = True , extra_props = None , eager_load = False , thing_data = False ) : ids , single = tup ( ids , True ) bases = cls . _byID ( ids , data = data , return_dict = True , extra_props = extra_props ) values = bases . values ( ) if values and eager_load : for base in bases . values ( ) : base . _eagerly_loaded_data = True load_things ( values , thing_data ) if single : return bases [ ids [ 0 ] ] elif return_dict : return bases else : return filter ( None , ( bases . get ( i ) for i in ids ) ) def __init__ ( self , thing1 , thing2 , name , date = None , id = None , ** attrs ) : DataThing . __init__ ( self ) def id_and_obj ( in_thing ) : if isinstance ( in_thing , ( int , long ) ) : return in_thing else : return in_thing . _id with self . safe_set_attr : if id : self . _id = id self . _created = True self . _loaded = False if not date : date = datetime . now ( g . tz ) self . _thing1_id = id_and_obj ( thing1 ) self . _thing2_id = id_and_obj ( thing2 ) self . _name = name self . _date = date for k , v in attrs . iteritems ( ) : self . __setattr__ ( k , v , not self . _created ) def denormalize ( denorm , src , dest ) : if denorm : setattr ( dest , denorm [ 0 ] , getattr ( src , denorm [ 1 ] ) ) if not self . _created : denormalize ( denorm1 , thing2 , thing1 ) denormalize ( denorm2 , thing1 , thing2 ) def __getattr__ ( self , attr ) : if attr == '_thing1' : return self . _type1 . _byID ( self . _thing1_id , self . _eagerly_loaded_data ) elif attr == '_thing2' : return self . _type2 . _byID ( self . _thing2_id , self . _eagerly_loaded_data ) elif attr . startswith ( '_t1' ) : return getattr ( self . _thing1 , attr [ 3 : ] ) elif attr . startswith ( '_t2' ) : return getattr ( self . _thing2 , attr [ 3 : ] ) else : return DataThing . __getattr__ ( self , attr ) def __repr__ ( self ) : return ( '<%s %s: <%s %s> - <%s %s> %s>' % ( self . __class__ . __name__ , self . _name , self . _type1 . __name__ , self . _thing1_id , self . _type2 . __name__ , self . _thing2_id , if not self . _created else '\b' ) ) def _commit ( self ) : DataThing . _commit ( self ) if denorm1 : self . _thing1 . _commit ( denorm1 [ 0 ] ) if denorm2 : self . _thing2 . _commit ( denorm2 [ 0 ] ) cache . set ( thing_prefix ( self . __class__ . __name__ ) + str ( ( self . _thing1_id , self . _thing2_id , self . _name ) ) , self . _id ) def _delete ( self ) : tdb . del_rel ( self . _type_id , self . _id ) prefix = thing_prefix ( self . __class__ . __name__ ) cache . delete ( prefix + str ( self . _id ) ) cache . set ( prefix + str ( ( self . _thing1_id , self . _thing2_id , self . _name ) ) , None ) self . _name = 'un' + self . _name @ classmethod def _fast_query_timestamp_touch ( cls , thing1 ) : thing_utils . set_last_modified_for_cls ( thing1 , cls . _type_name ) @ classmethod def _can_skip_lookup ( cls , thing1 , thing2 ) : last_done = thing_utils . get_last_modified_for_cls ( thing1 , cls . _type_name ) if not last_done : return False if thing2 . _date > last_done : return True return False @ classmethod def _fast_query ( cls , thing1s , thing2s , name , data = True , eager_load = True , thing_data = False , timestamp_optimize = False ) : prefix = thing_prefix ( cls . __name__ ) thing1_dict = dict ( ( t . _id , t ) for t in tup ( thing1s ) ) thing2_dict = dict ( ( t . _id , t ) for t in tup ( thing2s ) ) thing1_ids = thing1_dict . keys ( ) thing2_ids = thing2_dict . keys ( ) name = tup ( name ) pairs = set ( ( x , y , n ) for x in thing1_ids for y in thing2_ids for n in name ) def items_db ( pairs ) : rel_ids = { } t1_ids = set ( ) t2_ids = set ( ) names = set ( ) for t1 , t2 , name in pairs : if timestamp_optimize and cls . _can_skip_lookup ( thing1_dict [ t1 ] , thing2_dict [ t2 ] ) : continue t1_ids . add ( t1 ) t2_ids . add ( t2 ) names . add ( name ) if t1_ids and t2_ids and names : q = cls . _query ( cls . c . _thing1_id == t1_ids , cls . c . _thing2_id == t2_ids , cls . c . _name == names , eager_load = eager_load , thing_data = thing_data , data = data ) else : q = [ ] for rel in q : rel_ids [ ( rel . _thing1_id , rel . _thing2_id , rel . _name ) ] = rel . _id for p in pairs : if p not in rel_ids : rel_ids [ p ] = None return rel_ids res = sgm ( cache , pairs , items_db , prefix ) cls . _byID ( filter ( None , res . values ( ) ) , data = data ) res_obj = { } for k , rid in res . iteritems ( ) : obj_key = ( thing1_dict [ k [ 0 ] ] , thing2_dict [ k [ 1 ] ] , k [ 2 ] ) res_obj [ obj_key ] = cls . _byID ( rid , data = data ) if rid else None return res_obj @ classmethod def _gay ( cls ) : return cls . _type1 == cls . _type2 @ classmethod def _build ( cls , id , bases ) : return cls ( bases . thing1_id , bases . thing2_id , bases . name , bases . date , id ) @ classmethod def _query ( cls , * a , ** kw ) : return Relations ( cls , * a , ** kw ) return RelationCls Relation . _type_prefix = 'r' class Query ( object ) : def __init__ ( self , kind , * rules , ** kw ) : self . _rules = [ ] self . _kind = kind self . _read_cache = kw . get ( 'read_cache' ) self . _write_cache = kw . get ( 'write_cache' ) self . _cache_time = kw . get ( 'cache_time' , 0 ) self . _stats_collector = kw . get ( 'stats_collector' ) self . _limit = kw . get ( 'limit' ) self . _data = kw . get ( 'data' ) self . _sort = kw . get ( 'sort' , ( ) ) self . _filter_primary_sort_only = kw . get ( 'filter_primary_sort_only' , False ) self . _filter ( * rules ) def _setsort ( self , sorts ) : sorts = tup ( sorts ) have_date = False op_sorts = [ ] for s in sorts : if not isinstance ( s , operators . sort ) : s = operators . asc ( s ) op_sorts . append ( s ) if s . col . endswith ( '_date' ) : have_date = True if op_sorts and not have_date : op_sorts . append ( operators . desc ( '_date' ) ) self . _sort_param = op_sorts return self def _getsort ( self ) : return self . _sort_param _sort = property ( _getsort , _setsort ) def _reverse ( self ) : for s in self . _sort : if isinstance ( s , operators . asc ) : s . __class__ = operators . desc else : s . __class__ = operators . asc def _list ( self , data = False ) : if data : self . _data = data return list ( self ) def _dir ( self , thing , reverse ) : ors = [ ] sorts = range ( len ( self . _sort ) ) if self . _filter_primary_sort_only : sorts = [ 0 ] for i in sorts : s = self . _sort [ i ] if isinstance ( s , operators . asc ) : op = operators . gt else : op = operators . lt if reverse : op = operators . gt if op == operators . lt else operators . lt ands = [ op ( s . col , s . col , getattr ( thing , s . col ) ) ] for j in range ( 0 , i ) : s = self . _sort [ j ] ands . append ( thing . c [ s . col ] == getattr ( thing , s . col ) ) ors . append ( operators . and_ ( * ands ) ) return self . _filter ( operators . or_ ( * ors ) ) def _before ( self , thing ) : return self . _dir ( thing , True ) def _after ( self , thing ) : return self . _dir ( thing , False ) def _count ( self ) : return self . _cursor ( ) . rowcount ( ) def _filter ( * a , ** kw ) : raise NotImplementedError def _cursor ( * a , ** kw ) : raise NotImplementedError def _iden ( self ) : i = str ( self . _sort ) + str ( self . _kind ) + str ( self . _limit ) if self . _rules : rules = copy ( self . _rules ) rules . sort ( ) for r in rules : i += str ( r ) return sha . new ( i ) . hexdigest ( ) def __iter__ ( self ) : used_cache = False if self . _stats_collector : self . _stats_collector . add ( self ) def _retrieve ( ) : return self . _cursor ( ) . fetchall ( ) names = lst = [ ] names = cache . get ( self . _iden ( ) ) if self . _read_cache else None if names is None and not self . _write_cache : lst = _retrieve ( ) elif names is None and self . _write_cache : with g . make_lock ( "lock_%s" % self . _iden ( ) ) : names = cache . get ( self . _iden ( ) , allow_local = False ) if self . _read_cache else None if names is None : lst = _retrieve ( ) cache . set ( self . _iden ( ) , [ x . _fullname for x in lst ] , self . _cache_time ) if names and not lst : lst = Thing . _by_fullname ( names , data = self . _data , return_dict = False ) for item in lst : yield item class Things ( Query ) : def __init__ ( self , kind , * rules , ** kw ) : self . _use_data = False Query . __init__ ( self , kind , * rules , ** kw ) def _filter ( self , * rules ) : for op in operators . op_iter ( rules ) : if not op . lval_name . startswith ( '_' ) : self . _use_data = True self . _rules += rules return self def _cursor ( self ) : get_cols = False params = ( self . _kind . _type_id , get_cols , self . _sort , self . _limit , self . _rules ) if self . _use_data : c = tdb . find_data ( * params ) else : c = tdb . find_things ( * params ) def row_fn ( rows ) : if get_cols : extra_props = { } for r in rows : for sc in ( s . col for s in self . _sort ) : props = extra_props . setdefault ( r . thing_id , { } ) props [ sc ] = getattr ( r , sc ) _ids = extra_props . keys ( ) else : _ids = rows extra_props = { } return self . _kind . _byID ( _ids , self . _data , False , extra_props ) return Results ( c , row_fn , True ) def load_things ( rels , load_data = False ) : rels = tup ( rels ) kind = rels [ 0 ] . __class__ t1_ids = set ( ) t2_ids = t1_ids if kind . _gay ( ) else set ( ) for rel in rels : t1_ids . add ( rel . _thing1_id ) t2_ids . add ( rel . _thing2_id ) kind . _type1 . _byID ( t1_ids , data = load_data ) if not kind . _gay ( ) : t2_items = kind . _type2 . _byID ( t2_ids , data = load_data ) class Relations ( Query ) : def __init__ ( self , kind , * rules , ** kw ) : self . _eager_load = kw . get ( 'eager_load' ) self . _thing_data = kw . get ( 'thing_data' ) Query . __init__ ( self , kind , * rules , ** kw ) def _filter ( self , * rules ) : self . _rules += rules return self def _eager ( self , eager , thing_data = False ) : self . _eager_load = eager self . _thing_data = thing_data return self def _make_rel ( self , rows ) : rels = self . _kind . _byID ( rows , self . _data , False ) if rels and self . _eager_load : for rel in rels : rel . _eagerly_loaded_data = True load_things ( rels , self . _thing_data ) return rels def _cursor ( self ) : c = tdb . find_rels ( self . _kind . _type_id , False , sort = self . _sort , limit = self . _limit , constraints = self . _rules ) return Results ( c , self . _make_rel , True ) class MultiCursor ( object ) : def __init__ ( self , * execute_params ) : self . _execute_params = execute_params self . _cursor = None def fetchone ( self ) : if not self . _cursor : self . _cursor = self . _execute ( * self . _execute_params ) return self . _cursor . next ( ) def fetchall ( self ) : if not self . _cursor : self . _cursor = self . _execute ( * self . _execute_params ) return [ i for i in self . _cursor ] class MergeCursor ( MultiCursor ) : def _execute ( self , cursors , sorts ) : def safe_next ( c ) : try : while True : try : return [ c , c . fetchone ( ) , False ] except NotFound : pass except StopIteration : return c , None , True def undone ( pairs ) : return [ p for p in pairs if not p [ 2 ] ] pairs = undone ( safe_next ( c ) for c in cursors ) while pairs : if len ( pairs ) == 1 : c , item , done = pair = pairs [ 0 ] while not done : yield item c , item , done = safe_next ( c ) pair [ : ] = c , item , done else : yield_pair = pairs [ 0 ] for s in sorts : col = s . col max_fn = min if isinstance ( s , operators . asc ) else max vals = [ ( getattr ( i [ 1 ] , col ) , i ) for i in pairs ] max_pair = vals [ 0 ] all_equal = True for pair in vals [ 1 : ] : if all_equal and pair [ 0 ] != max_pair [ 0 ] : all_equal = False max_pair = max_fn ( max_pair , pair , key = lambda x : x [ 0 ] ) if not all_equal : yield_pair = max_pair [ 1 ] break c , item , done = yield_pair yield item yield_pair [ : ] = safe_next ( c ) pairs = undone ( pairs ) raise StopIteration class MultiQuery ( Query ) : def __init__ ( self , queries , * rules , ** kw ) : self . _queries = queries Query . __init__ ( self , None , * rules , ** kw ) def _iden ( self ) : return '' . join ( q . _iden ( ) for q in self . _queries ) def _cursor ( self ) : raise NotImplementedError ( ) def _reverse ( self ) : for q in self . _queries : q . _reverse ( ) def _setdata ( self , data ) : for q in self . _queries : q . _data = data def _getdata ( self ) : if self . _queries : return self . _queries [ 0 ] . _data _data = property ( _getdata , _setdata ) def _setsort ( self , sorts ) : for q in self . _queries : q . _sort = deepcopy ( sorts ) def _getsort ( self ) : if self . _queries : return self . _queries [ 0 ] . _sort _sort = property ( _getsort , _setsort ) def _filter ( self , * rules ) : for q in self . _queries : q . _filter ( * rules ) def _getrules ( self ) : return [ q . _rules for q in self . _queries ] def _setrules ( self , rules ) : for q , r in zip ( self . _queries , rules ) : q . _rules = r _rules = property ( _getrules , _setrules ) def _getlimit ( self ) : return self . _queries [ 0 ] . _limit def _setlimit ( self , limit ) : for q in self . _queries : q . _limit = limit _limit = property ( _getlimit , _setlimit ) class Merge ( MultiQuery ) : def _cursor ( self ) : if ( any ( q . _sort for q in self . _queries ) and not reduce ( lambda x , y : ( x == y ) and x , ( q . _sort for q in self . _queries ) ) ) : raise "The sorts should be the same" return MergeCursor ( ( q . _cursor ( ) for q in self . _queries ) , self . _sort ) def MultiRelation ( name , * relations ) : rels_tmp = { } for rel in relations : t1 , t2 = rel . _type1 , rel . _type2 clsname = name + '_' + t1 . __name__ . lower ( ) + '_' + t2 . __name__ . lower ( ) cls = new . classobj ( clsname , ( rel , ) , { '__module__' : t1 . __module__ } ) setattr ( sys . modules [ t1 . __module__ ] , clsname , cls ) rels_tmp [ ( t1 , t2 ) ] = cls class MultiRelationCls ( object ) : c = operators . Slots ( ) rels = rels_tmp def __init__ ( self , thing1 , thing2 , * a , ** kw ) : r = self . rel ( thing1 , thing2 ) self . __class__ = r self . __init__ ( thing1 , thing2 , * a , ** kw ) @ classmethod def rel ( cls , thing1 , thing2 ) : t1 = thing1 if isinstance ( thing1 , ThingMeta ) else thing1 . __class__ t2 = thing2 if isinstance ( thing2 , ThingMeta ) else thing2 . __class__ return cls . rels [ ( t1 , t2 ) ] @ classmethod def _query ( cls , * rules , ** kw ) : queries = [ r . _query ( * rules , ** kw ) for r in cls . rels . values ( ) ] if "sort" in kw : print "sorting MultiRelations is not supported" return Merge ( queries ) @ classmethod def _fast_query ( cls , sub , obj , name , data = True , eager_load = True , thing_data = False , timestamp_optimize = False ) : def type_dict ( items ) : types = { } for i in items : types . setdefault ( i . __class__ , [ ] ) . append ( i ) return types sub_dict = type_dict ( tup ( sub ) ) obj_dict = type_dict ( tup ( obj ) ) res = { } for types , rel in cls . rels . iteritems ( ) : t1 , t2 = types if sub_dict . has_key ( t1 ) and obj_dict . has_key ( t2 ) : res . update ( rel . _fast_query ( sub_dict [ t1 ] , obj_dict [ t2 ] , name , data = data , eager_load = eager_load , thing_data = thing_data , timestamp_optimize = timestamp_optimize ) ) return res return MultiRelationCls
