import boto import time import uuid from StringIO import StringIO from threading import Thread def spawn ( function , * args , ** kwargs ) : t = Thread ( target = function , args = args , kwargs = kwargs ) t . start ( ) return t def put_object ( bucket , name ) : bucket . new_key ( name ) . set_contents_from_string ( name ) def get_object ( bucket , name ) : assert bucket . get_key ( name ) . get_contents_as_string ( ) == name def test_close_connections ( ) : print "Running test_close_connections" s3 = boto . connect_s3 ( ) for b in s3 . get_all_buckets ( ) : if b . name . startswith ( 'test-' ) : for key in b . get_all_keys ( ) : key . delete ( ) b . delete ( ) bucket = s3 . create_bucket ( 'test-%d' % int ( time . time ( ) ) ) names = [ str ( uuid . uuid4 ) for _ in range ( 30 ) ] threads = [ spawn ( put_object , bucket , name ) for name in names ] for t in threads : t . join ( ) threads = [ spawn ( get_object , bucket , name ) for name in names ] for t in threads : t . join ( ) BIG_SIZE = 10000 class WriteAndCount ( object ) : def __init__ ( self ) : self . size = 0 def write ( self , data ) : self . size += len ( data ) time . sleep ( 0 ) def read_big_object ( s3 , bucket , name , count ) : for _ in range ( count ) : key = bucket . get_key ( name ) out = WriteAndCount ( ) key . get_contents_to_file ( out ) if out . size != BIG_SIZE : print out . size , BIG_SIZE assert out . size == BIG_SIZE print " pool size:" , s3 . _pool . size ( ) class LittleQuerier ( object ) : def __init__ ( self , bucket , small_names ) : self . running = True self . bucket = bucket self . small_names = small_names self . thread = spawn ( self . run ) def stop ( self ) : self . running = False self . thread . join ( ) def run ( self ) : count = 0 while self . running : i = count % 4 key = self . bucket . get_key ( self . small_names [ i ] ) expected = str ( i ) rh = { 'response-content-type' : 'small/' + str ( i ) } actual = key . get_contents_as_string ( response_headers = rh ) if expected != actual : print "AHA:" , repr ( expected ) , repr ( actual ) assert expected == actual count += 1 def test_reuse_connections ( ) : print "Running test_reuse_connections" s3 = boto . connect_s3 ( ) bucket = s3 . create_bucket ( 'test-%d' % int ( time . time ( ) ) ) small_names = [ str ( uuid . uuid4 ( ) ) for _ in range ( 4 ) ] for ( i , name ) in enumerate ( small_names ) : bucket . new_key ( name ) . set_contents_from_string ( str ( i ) ) print " waiting for all connections to become stale" time . sleep ( s3 . _pool . STALE_DURATION + 1 ) s3 . _pool . clean ( ) assert s3 . _pool . size ( ) == 0 print " pool is empty" big_name = str ( uuid . uuid4 ( ) ) contents = "-" * BIG_SIZE bucket . new_key ( big_name ) . set_contents_from_string ( contents ) threads = [ spawn ( read_big_object , s3 , bucket , big_name , 20 ) for _ in range ( 5 ) ] queriers = [ LittleQuerier ( bucket , small_names ) for _ in range ( 5 ) ] for t in threads : t . join ( ) for q in queriers : q . stop ( ) def main ( ) : test_close_connections ( ) test_reuse_connections ( ) if __name__ == '__main__' : main ( )
