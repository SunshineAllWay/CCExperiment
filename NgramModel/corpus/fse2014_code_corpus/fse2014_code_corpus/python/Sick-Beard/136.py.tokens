from __future__ import with_statement __author__ = "dbr/Ben" __version__ = "1.5" import os import time import errno import httplib import urllib2 import StringIO from hashlib import md5 from threading import RLock cache_lock = RLock ( ) def locked_function ( origfunc ) : def wrapped ( * args , ** kwargs ) : cache_lock . acquire ( ) try : return origfunc ( * args , ** kwargs ) finally : cache_lock . release ( ) return wrapped def calculate_cache_path ( cache_location , url ) : thumb = md5 ( url ) . hexdigest ( ) header = os . path . join ( cache_location , thumb + ".headers" ) body = os . path . join ( cache_location , thumb + ".body" ) return header , body def check_cache_time ( path , max_age ) : if not os . path . isfile ( path ) : return False cache_modified_time = os . stat ( path ) . st_mtime time_now = time . time ( ) if cache_modified_time < time_now - max_age : return False else : return True @ locked_function def exists_in_cache ( cache_location , url , max_age ) : hpath , bpath = calculate_cache_path ( cache_location , url ) if os . path . exists ( hpath ) and os . path . exists ( bpath ) : return ( check_cache_time ( hpath , max_age ) and check_cache_time ( bpath , max_age ) ) else : return False @ locked_function def store_in_cache ( cache_location , url , response ) : hpath , bpath = calculate_cache_path ( cache_location , url ) try : outf = open ( hpath , "w" ) headers = str ( response . info ( ) ) outf . write ( headers ) outf . close ( ) outf = open ( bpath , "w" ) outf . write ( response . read ( ) ) outf . close ( ) except IOError : return True else : return False class CacheHandler ( urllib2 . BaseHandler ) : @ locked_function def __init__ ( self , cache_location , max_age = 21600 ) : self . max_age = max_age self . cache_location = cache_location if not os . path . exists ( self . cache_location ) : try : os . mkdir ( self . cache_location ) except OSError , e : if e . errno == errno . EEXIST and os . path . isdir ( self . cache_location ) : pass else : raise def default_open ( self , request ) : if request . get_method ( ) is not "GET" : return None if exists_in_cache ( self . cache_location , request . get_full_url ( ) , self . max_age ) : return CachedResponse ( self . cache_location , request . get_full_url ( ) , set_cache_header = True ) else : return None def http_response ( self , request , response ) : if ( request . get_method ( ) == "GET" and str ( response . code ) . startswith ( "2" ) ) : if 'x-local-cache' not in response . info ( ) : set_cache_header = store_in_cache ( self . cache_location , request . get_full_url ( ) , response ) else : set_cache_header = True return CachedResponse ( self . cache_location , request . get_full_url ( ) , set_cache_header = set_cache_header ) else : return response class CachedResponse ( StringIO . StringIO ) : @ locked_function def __init__ ( self , cache_location , url , set_cache_header = True ) : self . cache_location = cache_location hpath , bpath = calculate_cache_path ( cache_location , url ) StringIO . StringIO . __init__ ( self , file ( bpath ) . read ( ) ) self . url = url self . code = 200 self . msg = "OK" headerbuf = file ( hpath ) . read ( ) if set_cache_header : headerbuf += "x-local-cache: %s\r\n" % ( bpath ) self . headers = httplib . HTTPMessage ( StringIO . StringIO ( headerbuf ) ) def info ( self ) : return self . headers def geturl ( self ) : return self . url @ locked_function def recache ( self ) : new_request = urllib2 . urlopen ( self . url ) set_cache_header = store_in_cache ( self . cache_location , new_request . url , new_request ) CachedResponse . __init__ ( self , self . cache_location , self . url , True ) if __name__ == "__main__" : def main ( ) : opener = urllib2 . build_opener ( CacheHandler ( "/tmp/" ) ) response = opener . open ( "http://google.com" ) print response . headers print "Response:" , response . read ( ) response . recache ( ) print response . headers print "After recache:" , response . read ( ) from threading import Thread class CacheThreadTest ( Thread ) : lastdata = None def run ( self ) : req = opener . open ( "http://google.com" ) newdata = req . read ( ) if self . lastdata is None : self . lastdata = newdata assert self . lastdata == newdata , "Data was not consistent, uhoh" req . recache ( ) threads = [ CacheThreadTest ( ) for x in range ( 50 ) ] print "Starting threads" [ t . start ( ) for t in threads ] print "..done" print "Joining threads" [ t . join ( ) for t in threads ] print "..done" main ( )
