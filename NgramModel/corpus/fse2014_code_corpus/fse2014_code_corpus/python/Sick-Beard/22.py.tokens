from __future__ import with_statement import glob import os import re import shlex import subprocess import sickbeard from sickbeard import db from sickbeard import classes from sickbeard import common from sickbeard import exceptions from sickbeard import helpers from sickbeard import history from sickbeard import logger from sickbeard import notifiers from sickbeard import show_name_helpers from sickbeard import scene_exceptions from sickbeard import encodingKludge as ek from sickbeard . exceptions import ex from sickbeard . name_parser . parser import NameParser , InvalidNameException from lib . tvdb_api import tvdb_api , tvdb_exceptions class PostProcessor ( object ) : EXISTS_LARGER = 1 EXISTS_SAME = 2 EXISTS_SMALLER = 3 DOESNT_EXIST = 4 def __init__ ( self , file_path , nzb_name = None ) : self . folder_path = ek . ek ( os . path . dirname , ek . ek ( os . path . abspath , file_path ) ) self . file_path = file_path self . file_name = ek . ek ( os . path . basename , file_path ) self . folder_name = ek . ek ( os . path . basename , self . folder_path ) self . nzb_name = nzb_name self . in_history = False self . release_group = None self . is_proper = False self . log = '' def _log ( self , message , level = logger . MESSAGE ) : logger . log ( message , level ) self . log += message + '\n' def _checkForExistingFile ( self , existing_file ) : if not existing_file : self . _log ( u"There is no existing file so there's no worries about replacing it" , logger . DEBUG ) return PostProcessor . DOESNT_EXIST if ek . ek ( os . path . isfile , existing_file ) : if ek . ek ( os . path . getsize , existing_file ) > ek . ek ( os . path . getsize , self . file_path ) : self . _log ( u"File " + existing_file + " is larger than " + self . file_path , logger . DEBUG ) return PostProcessor . EXISTS_LARGER elif ek . ek ( os . path . getsize , existing_file ) == ek . ek ( os . path . getsize , self . file_path ) : self . _log ( u"File " + existing_file + " is the same size as " + self . file_path , logger . DEBUG ) return PostProcessor . EXISTS_SAME else : self . _log ( u"File " + existing_file + " is smaller than " + self . file_path , logger . DEBUG ) return PostProcessor . EXISTS_SMALLER else : self . _log ( u"File " + existing_file + " doesn't exist so there's no worries about replacing it" , logger . DEBUG ) return PostProcessor . DOESNT_EXIST def _list_associated_files ( self , file_path ) : if not file_path : return [ ] file_path_list = [ ] base_name = file_path . rpartition ( '.' ) [ 0 ] + '.' base_name = re . sub ( r'[\[\]\*\?]' , r'[\g<0>]' , base_name ) for associated_file_path in ek . ek ( glob . glob , base_name + '*' ) : if '.' in associated_file_path [ len ( base_name ) : ] : continue file_path_list . append ( associated_file_path ) return file_path_list def _delete ( self , file_path , associated_files = False ) : if not file_path : return if associated_files : file_list = self . _list_associated_files ( file_path ) else : file_list = [ file_path ] if not file_list : self . _log ( u"There were no files associated with " + file_path + ", not deleting anything" , logger . DEBUG ) return for cur_file in file_list : self . _log ( u"Deleting file " + cur_file , logger . DEBUG ) if ek . ek ( os . path . isfile , cur_file ) : ek . ek ( os . remove , cur_file ) def _combined_file_operation ( self , file_path , new_path , new_base_name , associated_files = False , action = None ) : if not action : self . _log ( u"Must provide an action for the combined file operation" , logger . ERROR ) return if associated_files : file_list = self . _list_associated_files ( file_path ) else : file_list = [ file_path ] if not file_list : self . _log ( u"There were no files associated with " + file_path + ", not moving anything" , logger . DEBUG ) return for cur_file_path in file_list : cur_file_name = ek . ek ( os . path . basename , cur_file_path ) cur_extension = cur_file_path . rpartition ( '.' ) [ - 1 ] if cur_extension == 'nfo' : cur_extension = 'nfo-orig' if new_base_name : new_file_name = new_base_name + '.' + cur_extension else : new_file_name = helpers . replaceExtension ( cur_file_name , cur_extension ) new_file_path = ek . ek ( os . path . join , new_path , new_file_name ) action ( cur_file_path , new_file_path ) def _move ( self , file_path , new_path , new_base_name , associated_files = False ) : def _int_move ( cur_file_path , new_file_path ) : self . _log ( u"Moving file from " + cur_file_path + " to " + new_file_path , logger . DEBUG ) try : helpers . moveFile ( cur_file_path , new_file_path ) helpers . chmodAsParent ( new_file_path ) except ( IOError , OSError ) , e : self . _log ( "Unable to move file " + cur_file_path + " to " + new_file_path + ": " + ex ( e ) , logger . ERROR ) raise e self . _combined_file_operation ( file_path , new_path , new_base_name , associated_files , action = _int_move ) def _copy ( self , file_path , new_path , new_base_name , associated_files = False ) : def _int_copy ( cur_file_path , new_file_path ) : self . _log ( u"Copying file from " + cur_file_path + " to " + new_file_path , logger . DEBUG ) try : helpers . copyFile ( cur_file_path , new_file_path ) helpers . chmodAsParent ( new_file_path ) except ( IOError , OSError ) , e : logger . log ( "Unable to copy file " + cur_file_path + " to " + new_file_path + ": " + ex ( e ) , logger . ERROR ) raise e self . _combined_file_operation ( file_path , new_path , new_base_name , associated_files , action = _int_copy ) def _find_ep_destination_folder ( self , ep_obj ) : season_folder = '' if ep_obj . show . seasonfolders : for curDir in ek . ek ( os . listdir , ep_obj . show . location ) : if not ek . ek ( os . path . isdir , ek . ek ( os . path . join , ep_obj . show . location , curDir ) ) : continue match = re . match ( ".*season\s*(\d+)" , curDir , re . IGNORECASE ) if match : if int ( match . group ( 1 ) ) == int ( ep_obj . season ) : season_folder = curDir break if season_folder == '' : if ep_obj . show . air_by_date : season_folder = str ( ep_obj . airdate . year ) else : try : season_folder = sickbeard . SEASON_FOLDERS_FORMAT % ( ep_obj . season ) except TypeError : logger . log ( u"Error: Your season folder format is incorrect, try setting it back to the default" ) dest_folder = ek . ek ( os . path . join , ep_obj . show . location , season_folder ) return dest_folder def _history_lookup ( self ) : to_return = ( None , None , [ ] ) if not self . nzb_name and not self . folder_name : self . in_history = False return to_return names = [ ] if self . nzb_name : names . append ( self . nzb_name ) if '.' in self . nzb_name : names . append ( self . nzb_name . rpartition ( "." ) [ 0 ] ) if self . folder_name : names . append ( self . folder_name ) myDB = db . DBConnection ( ) for curName in names : sql_results = myDB . select ( "SELECT * FROM history WHERE resource LIKE ?" , [ re . sub ( "[\.\-\ ]" , "_" , curName ) ] ) if len ( sql_results ) == 0 : continue tvdb_id = int ( sql_results [ 0 ] [ "showid" ] ) season = int ( sql_results [ 0 ] [ "season" ] ) self . in_history = True to_return = ( tvdb_id , season , [ ] ) self . _log ( "Found result in history: " + str ( to_return ) , logger . DEBUG ) return to_return self . in_history = False return to_return def _analyze_name ( self , name , file = True ) : logger . log ( u"Analyzing name " + repr ( name ) ) to_return = ( None , None , [ ] ) if not name : return to_return np = NameParser ( file ) parse_result = np . parse ( name ) self . _log ( "Parsed " + name + " into " + str ( parse_result ) . decode ( 'utf-8' ) , logger . DEBUG ) if parse_result . air_by_date : season = - 1 episodes = [ parse_result . air_date ] else : season = parse_result . season_number episodes = parse_result . episode_numbers to_return = ( None , season , episodes ) name_list = show_name_helpers . sceneToNormalShowNames ( parse_result . series_name ) if not name_list : return ( None , season , episodes ) def _finalize ( parse_result ) : self . release_group = parse_result . release_group if parse_result . extra_info : self . is_proper = re . search ( '(^|[\. _-])(proper|repack)([\. _-]|$)' , parse_result . extra_info , re . I ) != None for cur_name in name_list : self . _log ( u"Checking scene exceptions for a match on " + cur_name , logger . DEBUG ) scene_id = scene_exceptions . get_scene_exception_by_name ( cur_name ) if scene_id : self . _log ( u"Scene exception lookup got tvdb id " + str ( scene_id ) + u", using that" , logger . DEBUG ) _finalize ( parse_result ) return ( scene_id , season , episodes ) for cur_name in name_list : self . _log ( u"Looking up " + cur_name + u" in the DB" , logger . DEBUG ) db_result = helpers . searchDBForShow ( cur_name ) if db_result : self . _log ( u"Lookup successful, using tvdb id " + str ( db_result [ 0 ] ) , logger . DEBUG ) _finalize ( parse_result ) return ( int ( db_result [ 0 ] ) , season , episodes ) for cur_name in name_list : try : t = tvdb_api . Tvdb ( custom_ui = classes . ShowListUI , ** sickbeard . TVDB_API_PARMS ) self . _log ( u"Looking up name " + cur_name + u" on TVDB" , logger . DEBUG ) showObj = t [ cur_name ] except ( tvdb_exceptions . tvdb_exception ) : try : ltvdb_api_parms = sickbeard . TVDB_API_PARMS . copy ( ) ltvdb_api_parms [ 'search_all_languages' ] = True t = tvdb_api . Tvdb ( custom_ui = classes . ShowListUI , ** ltvdb_api_parms ) self . _log ( u"Looking up name " + cur_name + u" in all languages on TVDB" , logger . DEBUG ) showObj = t [ cur_name ] except ( tvdb_exceptions . tvdb_exception , IOError ) : pass continue except ( IOError ) : continue self . _log ( u"Lookup successful, using tvdb id " + str ( showObj [ "id" ] ) , logger . DEBUG ) _finalize ( parse_result ) return ( int ( showObj [ "id" ] ) , season , episodes ) _finalize ( parse_result ) return to_return def _find_info ( self ) : tvdb_id = season = None episodes = [ ] attempt_list = [ self . _history_lookup , lambda : self . _analyze_name ( self . file_path ) , lambda : self . _analyze_name ( self . file_name ) , lambda : self . _analyze_name ( self . folder_name ) , lambda : self . _analyze_name ( self . file_path ) , lambda : self . _analyze_name ( self . nzb_name ) , ] for cur_attempt in attempt_list : try : ( cur_tvdb_id , cur_season , cur_episodes ) = cur_attempt ( ) except InvalidNameException , e : logger . log ( u"Unable to parse, skipping: " + ex ( e ) , logger . DEBUG ) continue if cur_tvdb_id and not ( self . in_history and tvdb_id ) : tvdb_id = cur_tvdb_id if cur_season != None : season = cur_season if cur_episodes : episodes = cur_episodes if season == - 1 and tvdb_id and episodes : self . _log ( u"Looks like this is an air-by-date show, attempting to convert the date to season/episode" , logger . DEBUG ) tvdb_lang = None try : showObj = helpers . findCertainShow ( sickbeard . showList , tvdb_id ) if ( showObj != None ) : tvdb_lang = showObj . lang except exceptions . MultipleShowObjectsException : raise try : ltvdb_api_parms = sickbeard . TVDB_API_PARMS . copy ( ) if tvdb_lang and not tvdb_lang == 'en' : ltvdb_api_parms [ 'language' ] = tvdb_lang t = tvdb_api . Tvdb ( ** ltvdb_api_parms ) epObj = t [ tvdb_id ] . airedOn ( episodes [ 0 ] ) [ 0 ] season = int ( epObj [ "seasonnumber" ] ) episodes = [ int ( epObj [ "episodenumber" ] ) ] self . _log ( u"Got season " + str ( season ) + " episodes " + str ( episodes ) , logger . DEBUG ) except tvdb_exceptions . tvdb_episodenotfound , e : self . _log ( u"Unable to find episode with date " + str ( episodes [ 0 ] ) + u" for show " + str ( tvdb_id ) + u", skipping" , logger . DEBUG ) episodes = [ ] continue elif season == None and tvdb_id : myDB = db . DBConnection ( ) numseasonsSQlResult = myDB . select ( "SELECT COUNT(DISTINCT season) as numseasons FROM tv_episodes WHERE showid = ? and season != 0" , [ tvdb_id ] ) if int ( numseasonsSQlResult [ 0 ] [ 0 ] ) == 1 and season == None : self . _log ( u"Don't have a season number, but this show appears to only have 1 season, setting seasonnumber to 1..." , logger . DEBUG ) season = 1 if tvdb_id and season != None and episodes : return ( tvdb_id , season , episodes ) return ( tvdb_id , season , episodes ) def _get_ep_obj ( self , tvdb_id , season , episodes ) : show_obj = None self . _log ( u"Loading show object for tvdb_id " + str ( tvdb_id ) , logger . DEBUG ) try : show_obj = helpers . findCertainShow ( sickbeard . showList , tvdb_id ) except exceptions . MultipleShowObjectsException : raise if not show_obj : self . _log ( u"This show isn't in your list, you need to add it to SB before post-processing an episode" , logger . ERROR ) raise exceptions . PostProcessingFailed ( ) root_ep = None for cur_episode in episodes : episode = int ( cur_episode ) self . _log ( u"Retrieving episode object for " + str ( season ) + "x" + str ( episode ) , logger . DEBUG ) try : curEp = show_obj . getEpisode ( season , episode ) except exceptions . EpisodeNotFoundException , e : self . _log ( u"Unable to create episode: " + ex ( e ) , logger . DEBUG ) raise exceptions . PostProcessingFailed ( ) if root_ep == None : root_ep = curEp root_ep . relatedEps = [ ] else : root_ep . relatedEps . append ( curEp ) return root_ep def _get_quality ( self , ep_obj ) : ep_quality = common . Quality . UNKNOWN if ep_obj . status in common . Quality . SNATCHED + common . Quality . SNATCHED_PROPER : oldStatus , ep_quality = common . Quality . splitCompositeStatus ( ep_obj . status ) if ep_quality != common . Quality . UNKNOWN : self . _log ( u"The old status had a quality in it, using that: " + common . Quality . qualityStrings [ ep_quality ] , logger . DEBUG ) return ep_quality name_list = [ self . nzb_name , self . folder_name , self . file_name ] for cur_name in name_list : if not cur_name : continue ep_quality = common . Quality . nameQuality ( cur_name ) self . _log ( u"Looking up quality for name " + cur_name + u", got " + common . Quality . qualityStrings [ ep_quality ] , logger . DEBUG ) if ep_quality != common . Quality . UNKNOWN : logger . log ( cur_name + u" looks like it has quality " + common . Quality . qualityStrings [ ep_quality ] + ", using that" , logger . DEBUG ) return ep_quality ep_quality = common . Quality . assumeQuality ( self . file_name ) self . _log ( u"Guessing quality for name " + self . file_name + u", got " + common . Quality . qualityStrings [ ep_quality ] , logger . DEBUG ) if ep_quality != common . Quality . UNKNOWN : logger . log ( self . file_name + u" looks like it has quality " + common . Quality . qualityStrings [ ep_quality ] + ", using that" , logger . DEBUG ) return ep_quality return ep_quality def _run_extra_scripts ( self , ep_obj ) : for curScriptName in sickbeard . EXTRA_SCRIPTS : script_cmd = shlex . split ( curScriptName ) + [ ep_obj . location , self . file_path , str ( ep_obj . show . tvdbid ) , str ( ep_obj . season ) , str ( ep_obj . episode ) , str ( ep_obj . airdate ) ] self . _log ( u"Executing command " + str ( script_cmd ) ) self . _log ( u"Absolute path to script: " + ek . ek ( os . path . abspath , script_cmd [ 0 ] ) , logger . DEBUG ) try : p = subprocess . Popen ( script_cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , cwd = sickbeard . PROG_DIR ) out , err = p . communicate ( ) self . _log ( u"Script result: " + str ( out ) , logger . DEBUG ) except OSError , e : self . _log ( u"Unable to run extra_script: " + ex ( e ) ) def _is_priority ( self , ep_obj , new_ep_quality ) : if self . in_history or ep_obj . status in common . Quality . SNATCHED + common . Quality . SNATCHED_PROPER : self . _log ( u"SB snatched this episode so I'm marking it as priority" , logger . DEBUG ) return True if new_ep_quality > ep_obj and new_ep_quality != common . Quality . UNKNOWN : self . _log ( u"This was manually downloaded but it appears to be better quality than what we have so I'm marking it as priority" , logger . DEBUG ) return True old_ep_status , old_ep_quality = common . Quality . splitCompositeStatus ( ep_obj . status ) if self . is_proper and new_ep_quality >= old_ep_quality : self . _log ( u"This was manually downloaded but it appears to be a proper so I'm marking it as priority" , logger . DEBUG ) return True return False def process ( self ) : self . _log ( u"Processing " + self . file_path + " (" + str ( self . nzb_name ) + ")" ) if os . path . isdir ( self . file_path ) : self . _log ( u"File " + self . file_path + " seems to be a directory" ) return False self . in_history = False ( tvdb_id , season , episodes ) = self . _find_info ( ) if not tvdb_id or season == None or not episodes : return False ep_obj = self . _get_ep_obj ( tvdb_id , season , episodes ) new_ep_quality = self . _get_quality ( ep_obj ) logger . log ( u"Quality of the episode we're processing: " + str ( new_ep_quality ) , logger . DEBUG ) priority_download = self . _is_priority ( ep_obj , new_ep_quality ) self . _log ( u"Is ep a priority download: " + str ( priority_download ) , logger . DEBUG ) for curEp in [ ep_obj ] + ep_obj . relatedEps : curEp . status = common . Quality . compositeStatus ( common . SNATCHED , new_ep_quality ) existing_file_status = self . _checkForExistingFile ( ep_obj . location ) if not priority_download : if existing_file_status in ( PostProcessor . EXISTS_LARGER , PostProcessor . EXISTS_SAME ) : self . _log ( u"File exists and we are not going to replace it because it's not smaller, quitting post-processing" , logger . DEBUG ) return False elif existing_file_status == PostProcessor . EXISTS_SMALLER : self . _log ( u"File exists and is smaller than the new file so I'm going to replace it" , logger . DEBUG ) elif existing_file_status != PostProcessor . DOESNT_EXIST : self . _log ( u"Unknown existing file status. This should never happen, please log this as a bug." , logger . ERROR ) return False else : self . _log ( u"This download is marked a priority download so I'm going to replace an existing file if I find one" , logger . DEBUG ) for cur_ep in [ ep_obj ] + ep_obj . relatedEps : try : self . _delete ( cur_ep . location , associated_files = True ) except OSError , IOError : raise exceptions . PostProcessingFailed ( "Unable to delete the existing files" ) try : dest_path = self . _find_ep_destination_folder ( ep_obj ) except exceptions . ShowDirNotFoundException : raise exceptions . PostProcessingFailed ( u"Unable to post-process an episode if the show dir doesn't exist, quitting" ) self . _log ( u"Destination folder for this episode: " + dest_path , logger . DEBUG ) if not ek . ek ( os . path . isdir , dest_path ) : self . _log ( u"Season folder didn't exist, creating it" , logger . DEBUG ) try : ek . ek ( os . mkdir , dest_path ) helpers . chmodAsParent ( dest_path ) except OSError , IOError : raise exceptions . PostProcessingFailed ( "Unable to create the episode's destination folder: " + dest_path ) for cur_ep in [ ep_obj ] + ep_obj . relatedEps : with cur_ep . lock : cur_ep . status = common . Quality . compositeStatus ( common . DOWNLOADED , new_ep_quality ) cur_ep . saveToDB ( ) if sickbeard . RENAME_EPISODES : orig_extension = self . file_name . rpartition ( '.' ) [ - 1 ] new_base_name = helpers . sanitizeFileName ( ep_obj . prettyName ( ) ) new_file_name = new_base_name + '.' + orig_extension else : new_base_name = None new_file_name = self . file_name try : if sickbeard . KEEP_PROCESSED_DIR : self . _copy ( self . file_path , dest_path , new_base_name , sickbeard . MOVE_ASSOCIATED_FILES ) else : self . _move ( self . file_path , dest_path , new_base_name , sickbeard . MOVE_ASSOCIATED_FILES ) except OSError , IOError : raise exceptions . PostProcessingFailed ( "Unable to move the files to their new home" ) for cur_ep in [ ep_obj ] + ep_obj . relatedEps : with cur_ep . lock : cur_ep . location = ek . ek ( os . path . join , dest_path , new_file_name ) cur_ep . saveToDB ( ) history . logDownload ( ep_obj , self . file_path ) notifiers . notify_download ( ep_obj . prettyName ( True ) ) ep_obj . createMetaFiles ( ) ep_obj . saveToDB ( ) notifiers . xbmc_notifier . update_library ( ep_obj . show . name ) notifiers . plex_notifier . update_library ( ) notifiers . synoindex_notifier . update_library ( ep_obj ) notifiers . trakt_notifier . update_library ( ep_obj ) notifiers . pytivo_notifier . update_library ( ep_obj ) self . _run_extra_scripts ( ep_obj ) return True
