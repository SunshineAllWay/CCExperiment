package org . apache . lucene . search ; import java . util . List ; import java . util . Arrays ; import java . io . IOException ; import org . apache . lucene . analysis . WhitespaceAnalyzer ; import org . apache . lucene . analysis . standard . StandardAnalyzer ; import org . apache . lucene . util . LuceneTestCase ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Field ; import org . apache . lucene . index . IndexWriter ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . IndexWriterConfig ; import org . apache . lucene . index . Term ; import org . apache . lucene . store . RAMDirectory ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . MockRAMDirectory ; import org . apache . lucene . queryParser . QueryParser ; public class TestFuzzyQuery extends LuceneTestCase { public void testFuzziness ( ) throws Exception { RAMDirectory directory = new RAMDirectory ( ) ; IndexWriter writer = new IndexWriter ( directory , new IndexWriterConfig ( TEST_VERSION_CURRENT , new WhitespaceAnalyzer ( TEST_VERSION_CURRENT ) ) ) ; addDoc ( "aaaaa" , writer ) ; addDoc ( "aaaab" , writer ) ; addDoc ( "aaabb" , writer ) ; addDoc ( "aabbb" , writer ) ; addDoc ( "abbbb" , writer ) ; addDoc ( "bbbbb" , writer ) ; addDoc ( "ddddd" , writer ) ; writer . optimize ( ) ; writer . close ( ) ; IndexSearcher searcher = new IndexSearcher ( directory , true ) ; FuzzyQuery query = new FuzzyQuery ( new Term ( "field" , "aaaaa" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; ScoreDoc [ ] hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaa" ) , FuzzyQuery . defaultMinSimilarity , 1 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaa" ) , FuzzyQuery . defaultMinSimilarity , 2 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaa" ) , FuzzyQuery . defaultMinSimilarity , 3 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaa" ) , FuzzyQuery . defaultMinSimilarity , 4 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 2 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaa" ) , FuzzyQuery . defaultMinSimilarity , 5 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaa" ) , FuzzyQuery . defaultMinSimilarity , 6 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "bbbbb" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( "3 documents should match" , 3 , hits . length ) ; List < String > order = Arrays . asList ( "bbbbb" , "abbbb" , "aabbb" ) ; for ( int i = 0 ; i < hits . length ; i ++ ) { final String term = searcher . doc ( hits [ i ] . doc ) . get ( "field" ) ; assertEquals ( order . get ( i ) , term ) ; } query = new FuzzyQuery ( new Term ( "field" , "bbbbb" ) , FuzzyQuery . defaultMinSimilarity , 0 , 2 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( "only 2 documents should match" , 2 , hits . length ) ; order = Arrays . asList ( "bbbbb" , "abbbb" ) ; for ( int i = 0 ; i < hits . length ; i ++ ) { final String term = searcher . doc ( hits [ i ] . doc ) . get ( "field" ) ; assertEquals ( order . get ( i ) , term ) ; } query = new FuzzyQuery ( new Term ( "field" , "xxxxx" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaccc" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaa" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "aaaaa" ) ) ; assertEquals ( searcher . doc ( hits [ 1 ] . doc ) . get ( "field" ) , ( "aaaab" ) ) ; assertEquals ( searcher . doc ( hits [ 2 ] . doc ) . get ( "field" ) , ( "aaabb" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaac" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "aaaaa" ) ) ; assertEquals ( searcher . doc ( hits [ 1 ] . doc ) . get ( "field" ) , ( "aaaab" ) ) ; assertEquals ( searcher . doc ( hits [ 2 ] . doc ) . get ( "field" ) , ( "aaabb" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaac" ) , FuzzyQuery . defaultMinSimilarity , 1 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "aaaaa" ) ) ; assertEquals ( searcher . doc ( hits [ 1 ] . doc ) . get ( "field" ) , ( "aaaab" ) ) ; assertEquals ( searcher . doc ( hits [ 2 ] . doc ) . get ( "field" ) , ( "aaabb" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaac" ) , FuzzyQuery . defaultMinSimilarity , 2 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "aaaaa" ) ) ; assertEquals ( searcher . doc ( hits [ 1 ] . doc ) . get ( "field" ) , ( "aaaab" ) ) ; assertEquals ( searcher . doc ( hits [ 2 ] . doc ) . get ( "field" ) , ( "aaabb" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaac" ) , FuzzyQuery . defaultMinSimilarity , 3 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "aaaaa" ) ) ; assertEquals ( searcher . doc ( hits [ 1 ] . doc ) . get ( "field" ) , ( "aaaab" ) ) ; assertEquals ( searcher . doc ( hits [ 2 ] . doc ) . get ( "field" ) , ( "aaabb" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaac" ) , FuzzyQuery . defaultMinSimilarity , 4 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 2 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "aaaaa" ) ) ; assertEquals ( searcher . doc ( hits [ 1 ] . doc ) . get ( "field" ) , ( "aaaab" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaac" ) , FuzzyQuery . defaultMinSimilarity , 5 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "ddddX" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "ddddd" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "ddddX" ) , FuzzyQuery . defaultMinSimilarity , 1 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "ddddd" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "ddddX" ) , FuzzyQuery . defaultMinSimilarity , 2 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "ddddd" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "ddddX" ) , FuzzyQuery . defaultMinSimilarity , 3 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "ddddd" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "ddddX" ) , FuzzyQuery . defaultMinSimilarity , 4 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "ddddd" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "ddddX" ) , FuzzyQuery . defaultMinSimilarity , 5 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "anotherfield" , "ddddX" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; searcher . close ( ) ; directory . close ( ) ; } public void testFuzzinessLong ( ) throws Exception { RAMDirectory directory = new RAMDirectory ( ) ; IndexWriter writer = new IndexWriter ( directory , new IndexWriterConfig ( TEST_VERSION_CURRENT , new WhitespaceAnalyzer ( TEST_VERSION_CURRENT ) ) ) ; addDoc ( "aaaaaaa" , writer ) ; addDoc ( "segment" , writer ) ; writer . optimize ( ) ; writer . close ( ) ; IndexSearcher searcher = new IndexSearcher ( directory , true ) ; FuzzyQuery query ; query = new FuzzyQuery ( new Term ( "field" , "xxxxx" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; ScoreDoc [ ] hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaccc" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "aaaaaaa" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaccc" ) , FuzzyQuery . defaultMinSimilarity , 1 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "aaaaaaa" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaccc" ) , FuzzyQuery . defaultMinSimilarity , 4 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; assertEquals ( searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) , ( "aaaaaaa" ) ) ; query = new FuzzyQuery ( new Term ( "field" , "aaaaccc" ) , FuzzyQuery . defaultMinSimilarity , 5 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaacccc" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "aaacccc" ) , FuzzyQuery . defaultMinSimilarity , 2 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "student" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "stellent" ) , FuzzyQuery . defaultMinSimilarity , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "student" ) , FuzzyQuery . defaultMinSimilarity , 1 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "stellent" ) , FuzzyQuery . defaultMinSimilarity , 1 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "student" ) , FuzzyQuery . defaultMinSimilarity , 2 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "stellent" ) , FuzzyQuery . defaultMinSimilarity , 2 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "student" ) , 0.6f , 0 ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; try { query = new FuzzyQuery ( new Term ( "field" , "student" ) , 1.1f ) ; fail ( "Expected IllegalArgumentException" ) ; } catch ( IllegalArgumentException e ) { } try { query = new FuzzyQuery ( new Term ( "field" , "student" ) , - 0.1f ) ; fail ( "Expected IllegalArgumentException" ) ; } catch ( IllegalArgumentException e ) { } searcher . close ( ) ; directory . close ( ) ; } public void testTokenLengthOpt ( ) throws IOException { RAMDirectory directory = new RAMDirectory ( ) ; IndexWriter writer = new IndexWriter ( directory , new IndexWriterConfig ( TEST_VERSION_CURRENT , new WhitespaceAnalyzer ( TEST_VERSION_CURRENT ) ) ) ; addDoc ( "12345678911" , writer ) ; addDoc ( "segment" , writer ) ; writer . optimize ( ) ; writer . close ( ) ; IndexSearcher searcher = new IndexSearcher ( directory , true ) ; Query query ; query = new FuzzyQuery ( new Term ( "field" , "1234569" ) , 0.9f ) ; ScoreDoc [ ] hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "1234567891" ) , 0.9f ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "12345678911" ) , 0.9f ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; query = new FuzzyQuery ( new Term ( "field" , "sdfsdfsdfsdf" ) , 0.9f ) ; hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 0 , hits . length ) ; } public void testBoostOnlyRewrite ( ) throws Exception { RAMDirectory directory = new RAMDirectory ( ) ; IndexWriter writer = new IndexWriter ( directory , new IndexWriterConfig ( TEST_VERSION_CURRENT , new WhitespaceAnalyzer ( TEST_VERSION_CURRENT ) ) ) ; addDoc ( "Lucene" , writer ) ; addDoc ( "Lucene" , writer ) ; addDoc ( "Lucenne" , writer ) ; writer . optimize ( ) ; writer . close ( ) ; IndexSearcher searcher = new IndexSearcher ( directory , true ) ; IndexReader reader = searcher . getIndexReader ( ) ; FuzzyQuery query = new FuzzyQuery ( new Term ( "field" , "Lucene" ) ) ; query . setRewriteMethod ( new MultiTermQuery . TopTermsBoostOnlyBooleanQueryRewrite ( ) ) ; ScoreDoc [ ] hits = searcher . search ( query , null , 1000 ) . scoreDocs ; assertEquals ( 3 , hits . length ) ; assertEquals ( "Lucene" , reader . document ( hits [ 0 ] . doc ) . get ( "field" ) ) ; assertEquals ( "Lucene" , reader . document ( hits [ 1 ] . doc ) . get ( "field" ) ) ; assertEquals ( "Lucenne" , reader . document ( hits [ 2 ] . doc ) . get ( "field" ) ) ; searcher . close ( ) ; reader . close ( ) ; } public void testGiga ( ) throws Exception { StandardAnalyzer analyzer = new StandardAnalyzer ( TEST_VERSION_CURRENT ) ; Directory index = new MockRAMDirectory ( ) ; IndexWriter w = new IndexWriter ( index , new IndexWriterConfig ( TEST_VERSION_CURRENT , analyzer ) ) ; addDoc ( "Lucene in Action" , w ) ; addDoc ( "Lucene for Dummies" , w ) ; addDoc ( "Giga byte" , w ) ; addDoc ( "ManagingGigabytesManagingGigabyte" , w ) ; addDoc ( "ManagingGigabytesManagingGigabytes" , w ) ; addDoc ( "The Art of Computer Science" , w ) ; addDoc ( "J. K. Rowling" , w ) ; addDoc ( "JK Rowling" , w ) ; addDoc ( "Joanne K Roling" , w ) ; addDoc ( "Bruce Willis" , w ) ; addDoc ( "Willis bruce" , w ) ; addDoc ( "Brute willis" , w ) ; addDoc ( "B. willis" , w ) ; IndexReader r = w . getReader ( ) ; w . close ( ) ; Query q = new QueryParser ( TEST_VERSION_CURRENT , "field" , analyzer ) . parse ( "giga~0.9" ) ; IndexSearcher searcher = new IndexSearcher ( r ) ; ScoreDoc [ ] hits = searcher . search ( q , 10 ) . scoreDocs ; assertEquals ( 1 , hits . length ) ; assertEquals ( "Giga byte" , searcher . doc ( hits [ 0 ] . doc ) . get ( "field" ) ) ; r . close ( ) ; } private void addDoc ( String text , IndexWriter writer ) throws IOException { Document doc = new Document ( ) ; doc . add ( new Field ( "field" , text , Field . Store . YES , Field . Index . ANALYZED ) ) ; writer . addDocument ( doc ) ; } }
